2026-01-22 00:55:48,470 INFO org.apache.hadoop.hdfs.server.namenode.NameNode (main): STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-39-172.ec2.internal/172.31.39.172
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.4.1-amzn-4
STARTUP_MSG:   classpath = /etc/hadoop/conf:/usr/lib/hadoop/lib/animal-sniffer-annotations-1.17.jar:/usr/lib/hadoop/lib/audience-annotations-0.12.0.jar:/usr/lib/hadoop/lib/avro-1.11.4.jar:/usr/lib/hadoop/lib/bcprov-jdk18on-1.78.1.jar:/usr/lib/hadoop/lib/checker-qual-2.5.2.jar:/usr/lib/hadoop/lib/commons-beanutils-1.9.4.jar:/usr/lib/hadoop/lib/commons-cli-1.5.0.jar:/usr/lib/hadoop/lib/commons-codec-1.15.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/commons-compress-1.26.1.jar:/usr/lib/hadoop/lib/commons-configuration2-2.10.1.jar:/usr/lib/hadoop/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop/lib/commons-io-2.16.1.jar:/usr/lib/hadoop/lib/commons-lang3-3.12.0.jar:/usr/lib/hadoop/lib/commons-logging-1.2.jar:/usr/lib/hadoop/lib/commons-math3-3.6.1.jar:/usr/lib/hadoop/lib/commons-net-3.9.0.jar:/usr/lib/hadoop/lib/commons-text-1.10.0.jar:/usr/lib/hadoop/lib/curator-client-5.2.0.jar:/usr/lib/hadoop/lib/curator-framework-5.2.0.jar:/usr/lib/hadoop/lib/curator-recipes-5.2.0.jar:/usr/lib/hadoop/lib/dnsjava-3.6.1.jar:/usr/lib/hadoop/lib/failureaccess-1.0.jar:/usr/lib/hadoop/lib/gson-2.9.0.jar:/usr/lib/hadoop/lib/guava-27.0-jre.jar:/usr/lib/hadoop/lib/httpclient-4.5.13.jar:/usr/lib/hadoop/lib/httpcore-4.4.13.jar:/usr/lib/hadoop/lib/j2objc-annotations-1.1.jar:/usr/lib/hadoop/lib/jackson-annotations-2.12.7.jar:/usr/lib/hadoop/lib/jackson-core-2.12.7.jar:/usr/lib/hadoop/lib/jackson-databind-2.12.7.1.jar:/usr/lib/hadoop/lib/jakarta.activation-api-1.2.1.jar:/usr/lib/hadoop/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop/lib/jersey-core-1.19.4.jar:/usr/lib/hadoop/lib/jersey-json-1.22.0.jar:/usr/lib/hadoop/lib/jersey-server-1.19.4.jar:/usr/lib/hadoop/lib/jersey-servlet-1.19.4.jar:/usr/lib/hadoop/lib/jettison-1.5.4.jar:/usr/lib/hadoop/lib/jetty-http-9.4.53.v20231009.jar:/usr/lib/hadoop/lib/jetty-io-9.4.53.v20231009.jar:/usr/lib/hadoop/lib/jetty-security-9.4.53.v20231009.jar:/usr/lib/hadoop/lib/jetty-server-9.4.53.v20231009.jar:/usr/lib/hadoop/lib/jetty-servlet-9.4.53.v20231009.jar:/usr/lib/hadoop/lib/jetty-util-9.4.53.v20231009.jar:/usr/lib/hadoop/lib/jetty-util-ajax-9.4.53.v20231009.jar:/usr/lib/hadoop/lib/jetty-webapp-9.4.53.v20231009.jar:/usr/lib/hadoop/lib/jetty-xml-9.4.53.v20231009.jar:/usr/lib/hadoop/lib/jsch-0.1.55.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.2.jar:/usr/lib/hadoop/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop/lib/jul-to-slf4j-1.7.36.jar:/usr/lib/hadoop/lib/kerb-core-2.0.3.jar:/usr/lib/hadoop/lib/kerb-crypto-2.0.3.jar:/usr/lib/hadoop/lib/kerb-util-2.0.3.jar:/usr/lib/hadoop/lib/kerby-asn1-2.0.3.jar:/usr/lib/hadoop/lib/kerby-config-2.0.3.jar:/usr/lib/hadoop/lib/kerby-pkix-2.0.3.jar:/usr/lib/hadoop/lib/kerby-util-2.0.3.jar:/usr/lib/hadoop/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/lib/hadoop/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop/lib/netty-all-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-buffer-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-codec-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-codec-dns-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-codec-haproxy-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-codec-http-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-codec-http2-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-codec-memcache-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-codec-mqtt-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-codec-redis-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-codec-smtp-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-codec-socks-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-codec-stomp-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-codec-xml-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-common-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-handler-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-handler-proxy-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-handler-ssl-ocsp-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-resolver-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-resolver-dns-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-resolver-dns-classes-macos-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-resolver-dns-native-macos-4.1.100.Final-osx-aarch_64.jar:/usr/lib/hadoop/lib/netty-resolver-dns-native-macos-4.1.100.Final-osx-x86_64.jar:/usr/lib/hadoop/lib/netty-transport-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-transport-classes-epoll-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-transport-classes-kqueue-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-transport-native-epoll-4.1.100.Final-linux-aarch_64.jar:/usr/lib/hadoop/lib/netty-transport-native-epoll-4.1.100.Final-linux-x86_64.jar:/usr/lib/hadoop/lib/netty-transport-native-epoll-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-transport-native-kqueue-4.1.100.Final-osx-aarch_64.jar:/usr/lib/hadoop/lib/netty-transport-native-kqueue-4.1.100.Final-osx-x86_64.jar:/usr/lib/hadoop/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-transport-rxtx-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-transport-sctp-4.1.100.Final.jar:/usr/lib/hadoop/lib/netty-transport-udt-4.1.100.Final.jar:/usr/lib/hadoop/lib/nimbus-jose-jwt-9.37.2.jar:/usr/lib/hadoop/lib/re2j-1.1.jar:/usr/lib/hadoop/lib/reload4j-1.2.22.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.36.jar:/usr/lib/hadoop/lib/slf4j-reload4j-1.7.36.jar:/usr/lib/hadoop/lib/snappy-java-1.1.10.4.jar:/usr/lib/hadoop/lib/stax2-api-4.2.1.jar:/usr/lib/hadoop/lib/woodstox-core-5.4.0.jar:/usr/lib/hadoop/lib/zookeeper-3.9.3-amzn-4.jar:/usr/lib/hadoop/lib/zookeeper-d*.jar:/usr/lib/hadoop/lib/zookeeper-jute-3.9.3-amzn-4.jar:/usr/lib/hadoop/.//hadoop-aliyun-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-aliyun.jar:/usr/lib/hadoop/.//hadoop-annotations-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-archive-logs-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-archive-logs.jar:/usr/lib/hadoop/.//hadoop-archives-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-archives.jar:/usr/lib/hadoop/.//hadoop-auth-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-aws-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//hadoop-azure-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-azure-datalake-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-azure-datalake.jar:/usr/lib/hadoop/.//hadoop-azure.jar:/usr/lib/hadoop/.//hadoop-client-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-client.jar:/usr/lib/hadoop/.//hadoop-common-3.4.1-amzn-4-tests.jar:/usr/lib/hadoop/.//hadoop-common-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-datajoin-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-datajoin.jar:/usr/lib/hadoop/.//hadoop-distcp-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-distcp.jar:/usr/lib/hadoop/.//hadoop-dynamometer-blockgen-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-dynamometer-blockgen.jar:/usr/lib/hadoop/.//hadoop-dynamometer-infra-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-dynamometer-infra.jar:/usr/lib/hadoop/.//hadoop-dynamometer-workload-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-dynamometer-workload.jar:/usr/lib/hadoop/.//hadoop-extras-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-extras.jar:/usr/lib/hadoop/.//hadoop-federation-balance-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-federation-balance.jar:/usr/lib/hadoop/.//hadoop-fs2img-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-fs2img.jar:/usr/lib/hadoop/.//hadoop-gridmix-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-gridmix.jar:/usr/lib/hadoop/.//hadoop-kafka-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-kafka.jar:/usr/lib/hadoop/.//hadoop-kms-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-kms.jar:/usr/lib/hadoop/.//hadoop-minicluster-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-minicluster.jar:/usr/lib/hadoop/.//hadoop-nfs-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-registry-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-registry.jar:/usr/lib/hadoop/.//hadoop-resourceestimator-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-resourceestimator.jar:/usr/lib/hadoop/.//hadoop-rumen-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-rumen.jar:/usr/lib/hadoop/.//hadoop-shaded-guava-1.3.0.jar:/usr/lib/hadoop/.//hadoop-shaded-protobuf_3_25-1.3.0.jar:/usr/lib/hadoop/.//hadoop-sls-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-sls.jar:/usr/lib/hadoop/.//hadoop-streaming-3.4.1-amzn-4.jar:/usr/lib/hadoop/.//hadoop-streaming.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/netty-transport-rxtx-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-transport-sctp-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-transport-udt-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/nimbus-jose-jwt-9.37.2.jar:/usr/lib/hadoop-hdfs/lib/re2j-1.1.jar:/usr/lib/hadoop-hdfs/lib/reload4j-1.2.22.jar:/usr/lib/hadoop-hdfs/lib/snappy-java-1.1.10.4.jar:/usr/lib/hadoop-hdfs/lib/stax2-api-4.2.1.jar:/usr/lib/hadoop-hdfs/lib/woodstox-core-5.4.0.jar:/usr/lib/hadoop-hdfs/lib/zookeeper-3.9.3-amzn-4.jar:/usr/lib/hadoop-hdfs/lib/zookeeper-jute-3.9.3-amzn-4.jar:/usr/lib/hadoop-hdfs/lib/HikariCP-4.0.3.jar:/usr/lib/hadoop-hdfs/lib/animal-sniffer-annotations-1.17.jar:/usr/lib/hadoop-hdfs/lib/audience-annotations-0.12.0.jar:/usr/lib/hadoop-hdfs/lib/avro-1.11.4.jar:/usr/lib/hadoop-hdfs/lib/checker-qual-2.5.2.jar:/usr/lib/hadoop-hdfs/lib/commons-beanutils-1.9.4.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.5.0.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.15.jar:/usr/lib/hadoop-hdfs/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-hdfs/lib/commons-compress-1.26.1.jar:/usr/lib/hadoop-hdfs/lib/commons-configuration2-2.10.1.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.16.1.jar:/usr/lib/hadoop-hdfs/lib/commons-lang3-3.12.0.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-math3-3.6.1.jar:/usr/lib/hadoop-hdfs/lib/commons-net-3.9.0.jar:/usr/lib/hadoop-hdfs/lib/commons-text-1.10.0.jar:/usr/lib/hadoop-hdfs/lib/curator-client-5.2.0.jar:/usr/lib/hadoop-hdfs/lib/curator-framework-5.2.0.jar:/usr/lib/hadoop-hdfs/lib/curator-recipes-5.2.0.jar:/usr/lib/hadoop-hdfs/lib/dnsjava-3.6.1.jar:/usr/lib/hadoop-hdfs/lib/failureaccess-1.0.jar:/usr/lib/hadoop-hdfs/lib/gson-2.9.0.jar:/usr/lib/hadoop-hdfs/lib/guava-27.0-jre.jar:/usr/lib/hadoop-hdfs/lib/httpclient-4.5.13.jar:/usr/lib/hadoop-hdfs/lib/httpcore-4.4.13.jar:/usr/lib/hadoop-hdfs/lib/j2objc-annotations-1.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-annotations-2.12.7.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-2.12.7.jar:/usr/lib/hadoop-hdfs/lib/jackson-databind-2.12.7.1.jar:/usr/lib/hadoop-hdfs/lib/jakarta.activation-api-1.2.1.jar:/usr/lib/hadoop-hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop-hdfs/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop-hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-hdfs/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.19.4.jar:/usr/lib/hadoop-hdfs/lib/jersey-json-1.22.0.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.19.4.jar:/usr/lib/hadoop-hdfs/lib/jersey-servlet-1.19.4.jar:/usr/lib/hadoop-hdfs/lib/jettison-1.5.4.jar:/usr/lib/hadoop-hdfs/lib/jetty-http-9.4.53.v20231009.jar:/usr/lib/hadoop-hdfs/lib/jetty-io-9.4.53.v20231009.jar:/usr/lib/hadoop-hdfs/lib/jetty-security-9.4.53.v20231009.jar:/usr/lib/hadoop-hdfs/lib/jetty-server-9.4.53.v20231009.jar:/usr/lib/hadoop-hdfs/lib/jetty-servlet-9.4.53.v20231009.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-9.4.53.v20231009.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-ajax-9.4.53.v20231009.jar:/usr/lib/hadoop-hdfs/lib/jetty-webapp-9.4.53.v20231009.jar:/usr/lib/hadoop-hdfs/lib/jetty-xml-9.4.53.v20231009.jar:/usr/lib/hadoop-hdfs/lib/jsch-0.1.55.jar:/usr/lib/hadoop-hdfs/lib/json-simple-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.2.jar:/usr/lib/hadoop-hdfs/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/kerb-core-2.0.3.jar:/usr/lib/hadoop-hdfs/lib/kerb-crypto-2.0.3.jar:/usr/lib/hadoop-hdfs/lib/kerb-util-2.0.3.jar:/usr/lib/hadoop-hdfs/lib/kerby-asn1-2.0.3.jar:/usr/lib/hadoop-hdfs/lib/kerby-config-2.0.3.jar:/usr/lib/hadoop-hdfs/lib/kerby-pkix-2.0.3.jar:/usr/lib/hadoop-hdfs/lib/kerby-util-2.0.3.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/lib/hadoop-hdfs/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-buffer-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-codec-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-codec-dns-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-codec-haproxy-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-codec-http-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-codec-http2-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-codec-memcache-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-codec-mqtt-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-codec-redis-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-codec-smtp-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-codec-socks-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-codec-stomp-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-codec-xml-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-common-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-handler-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-handler-proxy-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-handler-ssl-ocsp-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-resolver-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-resolver-dns-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-resolver-dns-classes-macos-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-resolver-dns-native-macos-4.1.100.Final-osx-aarch_64.jar:/usr/lib/hadoop-hdfs/lib/netty-resolver-dns-native-macos-4.1.100.Final-osx-x86_64.jar:/usr/lib/hadoop-hdfs/lib/netty-transport-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-transport-classes-epoll-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-transport-classes-kqueue-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-transport-native-epoll-4.1.100.Final-linux-aarch_64.jar:/usr/lib/hadoop-hdfs/lib/netty-transport-native-epoll-4.1.100.Final-linux-x86_64.jar:/usr/lib/hadoop-hdfs/lib/netty-transport-native-epoll-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-transport-native-kqueue-4.1.100.Final-osx-aarch_64.jar:/usr/lib/hadoop-hdfs/lib/netty-transport-native-kqueue-4.1.100.Final-osx-x86_64.jar:/usr/lib/hadoop-hdfs/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.4.1-amzn-4-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.4.1-amzn-4.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.4.1-amzn-4-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.4.1-amzn-4.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs-3.4.1-amzn-4.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.4.1-amzn-4-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.4.1-amzn-4.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-3.4.1-amzn-4.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.4.1-amzn-4-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.4.1-amzn-4.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-mapreduce/.//AIMDRateAdjuster-1.1-emr-0.jar:/usr/lib/hadoop-mapreduce/.//AIMDRateAdjusterRateLimiter-1.0.jar:/usr/lib/hadoop-mapreduce/.//RetryHelpersLib-2.1-emr-0.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-core-4.5.10.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-kms-2.11.0.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ram-3.1.0.jar:/usr/lib/hadoop-mapreduce/.//aliyun-sdk-oss-3.13.2.jar:/usr/lib/hadoop-mapreduce/.//azure-data-lake-store-sdk-2.3.9.jar:/usr/lib/hadoop-mapreduce/.//azure-keyvault-core-1.0.0.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-7.0.1.jar:/usr/lib/hadoop-mapreduce/.//findbugs-annotations-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-client-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-client.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-dynamometer-blockgen-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-dynamometer-blockgen.jar:/usr/lib/hadoop-mapreduce/.//hadoop-dynamometer-infra-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-dynamometer-infra.jar:/usr/lib/hadoop-mapreduce/.//hadoop-dynamometer-workload-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-dynamometer-workload.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//hadoop-federation-balance-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-federation-balance.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.4.1-amzn-4-tests.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-minicluster-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-minicluster.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-3.4.1-amzn-4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/.//ini4j-0.5.4.jar:/usr/lib/hadoop-mapreduce/.//jdk.tools-1.8.jar:/usr/lib/hadoop-mapreduce/.//jdom2-2.0.6.1.jar:/usr/lib/hadoop-mapreduce/.//junit-4.13.2.jar:/usr/lib/hadoop-mapreduce/.//kafka-clients-3.4.0.jar:/usr/lib/hadoop-mapreduce/.//lz4-java-1.7.1.jar:/usr/lib/hadoop-mapreduce/.//ojalgo-43.0.jar:/usr/lib/hadoop-mapreduce/.//opentracing-api-0.33.0.jar:/usr/lib/hadoop-mapreduce/.//opentracing-noop-0.33.0.jar:/usr/lib/hadoop-mapreduce/.//opentracing-util-0.33.0.jar:/usr/lib/hadoop-mapreduce/.//org.jacoco.agent-0.8.5-runtime.jar:/usr/lib/hadoop-mapreduce/.//wildfly-openssl-1.1.3.Final.jar:/usr/lib/hadoop-mapreduce/.//zstd-jni-1.5.2-1.jar:/usr/lib/hadoop-yarn/lib/FastInfoset-1.2.15.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/asm-commons-9.6.jar:/usr/lib/hadoop-yarn/lib/asm-tree-9.6.jar:/usr/lib/hadoop-yarn/lib/bcpkix-jdk18on-1.78.1.jar:/usr/lib/hadoop-yarn/lib/bcutil-jdk18on-1.78.1.jar:/usr/lib/hadoop-yarn/lib/cache-api-1.1.1.jar:/usr/lib/hadoop-yarn/lib/codemodel-2.6.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/ehcache-3.8.2.jar:/usr/lib/hadoop-yarn/lib/fst-2.50.jar:/usr/lib/hadoop-yarn/lib/guice-5.1.0.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-5.1.0.jar:/usr/lib/hadoop-yarn/lib/istack-commons-runtime-3.0.7.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-base-2.12.7.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/usr/lib/hadoop-yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/usr/lib/hadoop-yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/usr/lib/hadoop-yarn/lib/javax-websocket-client-impl-9.4.53.v20231009.jar:/usr/lib/hadoop-yarn/lib/javax-websocket-server-impl-9.4.53.v20231009.jar:/usr/lib/hadoop-yarn/lib/javax.activation-api-1.2.0.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/javax.websocket-api-1.0.jar:/usr/lib/hadoop-yarn/lib/javax.websocket-client-api-1.0.jar:/usr/lib/hadoop-yarn/lib/jaxb-runtime-2.3.1.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.19.4.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.19.4.jar:/usr/lib/hadoop-yarn/lib/jetty-annotations-9.4.53.v20231009.jar:/usr/lib/hadoop-yarn/lib/jetty-client-9.4.53.v20231009.jar:/usr/lib/hadoop-yarn/lib/jetty-jndi-9.4.53.v20231009.jar:/usr/lib/hadoop-yarn/lib/jetty-plus-9.4.53.v20231009.jar:/usr/lib/hadoop-yarn/lib/jline-3.9.0.jar:/usr/lib/hadoop-yarn/lib/jna-5.2.0.jar:/usr/lib/hadoop-yarn/lib/jsonschema2pojo-core-1.0.2.jar:/usr/lib/hadoop-yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/lib/hadoop-yarn/lib/objenesis-2.6.jar:/usr/lib/hadoop-yarn/lib/snakeyaml-2.0.jar:/usr/lib/hadoop-yarn/lib/stax-ex-1.8.jar:/usr/lib/hadoop-yarn/lib/swagger-annotations-1.5.4.jar:/usr/lib/hadoop-yarn/lib/txw2-2.3.1.jar:/usr/lib/hadoop-yarn/lib/websocket-api-9.4.53.v20231009.jar:/usr/lib/hadoop-yarn/lib/websocket-client-9.4.53.v20231009.jar:/usr/lib/hadoop-yarn/lib/websocket-common-9.4.53.v20231009.jar:/usr/lib/hadoop-yarn/lib/websocket-server-9.4.53.v20231009.jar:/usr/lib/hadoop-yarn/lib/websocket-servlet-9.4.53.v20231009.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-mawo-core-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-mawo-core.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-globalpolicygenerator-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-globalpolicygenerator.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core-3.4.1-amzn-4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core.jar:/usr/lib/hadoop-lzo/lib/hadoop-lzo-0.4.19.jar:/usr/lib/hadoop-lzo/lib/hadoop-lzo.jar:/usr/lib/hadoop-lzo/lib/native:/usr/share/aws/aws-java-sdk/LICENSE.txt:/usr/share/aws/aws-java-sdk/NOTICE.txt:/usr/share/aws/aws-java-sdk/README.md:/usr/share/aws/aws-java-sdk/aws-java-sdk-bundle-1.12.792.jar:/usr/share/aws/aws-java-sdk-v2/LICENSE.txt:/usr/share/aws/aws-java-sdk-v2/NOTICE.txt:/usr/share/aws/aws-java-sdk-v2/README.md:/usr/share/aws/aws-java-sdk-v2/aws-sdk-java-bundle-2.35.5.jar:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/animal-sniffer-annotations-1.14.jar:/usr/share/aws/emr/emrfs/lib/annotations-16.0.2.jar:/usr/share/aws/emr/emrfs/lib/aopalliance-1.0.jar:/usr/share/aws/emr/emrfs/lib/bcprov-ext-jdk15on-1.66.jar:/usr/share/aws/emr/emrfs/lib/checker-qual-2.5.2.jar:/usr/share/aws/emr/emrfs/lib/emrfs-hadoop-assembly-2.73.0.jar:/usr/share/aws/emr/emrfs/lib/error_prone_annotations-2.1.3.jar:/usr/share/aws/emr/emrfs/lib/findbugs-annotations-3.0.1.jar:/usr/share/aws/emr/emrfs/lib/j2objc-annotations-1.1.jar:/usr/share/aws/emr/emrfs/lib/javax.inject-1.jar:/usr/share/aws/emr/emrfs/lib/jmespath-java-1.12.705.jar:/usr/share/aws/emr/emrfs/lib/jsr305-3.0.2.jar:/usr/share/aws/emr/emrfs/lib/kryo-shaded-4.0.2.jar:/usr/share/aws/emr/emrfs/lib/minlog-1.3.0.jar:/usr/share/aws/emr/emrfs/lib/objenesis-2.5.1.jar:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/ddb/lib/emr-ddb-hadoop.jar:/usr/share/aws/emr/goodies/lib/emr-hadoop-goodies.jar:/usr/share/aws/emr/kinesis/lib/emr-kinesis-hadoop.jar:/usr/share/aws/emr/cloudwatch-sink/lib/cloudwatch-sink-2.22.0.jar:/usr/share/aws/emr/cloudwatch-sink/lib/cloudwatch-sink.jar
STARTUP_MSG:   build = https://git-codecommit.us-west-2.amazonaws.com/v1/repos/Aws157HadoopGit -r 5c02ad2129e6b2140b0caa509efc75b0d2015173; compiled by 'release' on 2025-11-26T23:05Z
STARTUP_MSG:   java = 17.0.17
************************************************************/
2026-01-22 00:55:48,477 INFO org.apache.hadoop.hdfs.server.namenode.NameNode (main): registered UNIX signal handlers for [TERM, HUP, INT]
2026-01-22 00:55:48,584 INFO org.apache.hadoop.hdfs.server.namenode.NameNode (main): createNameNode []
2026-01-22 00:55:48,797 INFO org.apache.hadoop.metrics2.impl.MetricsConfig (main): Loaded properties from hadoop-metrics2.properties
2026-01-22 00:55:48,802 INFO com.amazon.ws.emr.hadoop.metrics2.sink.cloudwatch.CloudWatchSink (main): Initializing the CloudWatchSink for metrics.
2026-01-22 00:55:49,082 INFO org.apache.hadoop.metrics2.impl.MetricsSinkAdapter (main): Sink cloudwatch started
2026-01-22 00:55:49,239 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl (main): Scheduled Metric snapshot period at 300 second(s).
2026-01-22 00:55:49,239 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl (main): NameNode metrics system started
2026-01-22 00:55:49,353 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils (main): fs.defaultFS is hdfs://ip-172-31-39-172.ec2.internal:8020
2026-01-22 00:55:49,354 INFO org.apache.hadoop.hdfs.server.namenode.NameNode (main): Clients should use ip-172-31-39-172.ec2.internal:8020 to access this namenode/service.
2026-01-22 00:55:49,480 INFO org.apache.hadoop.util.JvmPauseMonitor (org.apache.hadoop.util.JvmPauseMonitor$Monitor@7e809b79): Starting JVM pause monitor
2026-01-22 00:55:49,520 INFO org.apache.hadoop.hdfs.DFSUtil (main): Filter initializers set : org.apache.hadoop.security.HttpCrossOriginFilterInitializer,org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2026-01-22 00:55:49,532 INFO org.apache.hadoop.hdfs.DFSUtil (main): Starting Web-server for hdfs at: http://ip-172-31-39-172.ec2.internal:9870
2026-01-22 00:55:49,548 INFO org.eclipse.jetty.util.log (main): Logging initialized @1842ms to org.eclipse.jetty.util.log.Slf4jLog
2026-01-22 00:55:49,709 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter (main): Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /var/lib/hadoop-hdfs/hadoop-http-auth-signature-secret
2026-01-22 00:55:49,793 INFO org.apache.hadoop.http.HttpServer2 (main): Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2026-01-22 00:55:49,800 INFO org.apache.hadoop.security.HttpCrossOriginFilterInitializer (main): CORS filter not enabled. Please set hadoop.http.cross-origin.enabled to 'true' to enable it
2026-01-22 00:55:49,801 INFO org.apache.hadoop.http.HttpServer2 (main): Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2026-01-22 00:55:49,801 INFO org.apache.hadoop.http.HttpServer2 (main): Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2026-01-22 00:55:49,801 INFO org.apache.hadoop.http.HttpServer2 (main): Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2026-01-22 00:55:49,806 INFO org.apache.hadoop.http.HttpServer2 (main): Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2026-01-22 00:55:49,806 INFO org.apache.hadoop.http.HttpServer2 (main): Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2026-01-22 00:55:49,807 INFO org.apache.hadoop.http.HttpServer2 (main): Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2026-01-22 00:55:49,810 INFO org.apache.hadoop.http.HttpServer2 (main): ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2026-01-22 00:55:49,868 INFO org.apache.hadoop.http.HttpServer2 (main): addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2026-01-22 00:55:49,891 INFO org.apache.hadoop.http.HttpServer2 (main): Jetty bound to port 9870
2026-01-22 00:55:49,892 INFO org.eclipse.jetty.server.Server (main): jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 17.0.17+10-LTS
2026-01-22 00:55:49,954 INFO org.eclipse.jetty.server.session (main): DefaultSessionIdManager workerName=node0
2026-01-22 00:55:49,954 INFO org.eclipse.jetty.server.session (main): No SessionScavenger set, using defaults
2026-01-22 00:55:49,956 INFO org.eclipse.jetty.server.session (main): node0 Scavenging every 600000ms
2026-01-22 00:55:49,996 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter (main): Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /var/lib/hadoop-hdfs/hadoop-http-auth-signature-secret
2026-01-22 00:55:50,000 INFO org.eclipse.jetty.server.handler.ContextHandler (main): Started o.e.j.s.ServletContextHandler@26d10f2e{logs,/logs,file:///var/log/hadoop-hdfs/,AVAILABLE}
2026-01-22 00:55:50,001 INFO org.eclipse.jetty.server.handler.ContextHandler (main): Started o.e.j.s.ServletContextHandler@7bfc3126{static,/static,file:///usr/lib/hadoop-hdfs/webapps/static/,AVAILABLE}
2026-01-22 00:55:50,147 INFO org.eclipse.jetty.server.handler.ContextHandler (main): Started o.e.j.w.WebAppContext@301d8120{hdfs,/,file:///usr/lib/hadoop-hdfs/webapps/hdfs/,AVAILABLE}{file:/usr/lib/hadoop-hdfs/webapps/hdfs}
2026-01-22 00:55:50,163 INFO org.eclipse.jetty.server.AbstractConnector (main): Started ServerConnector@2237bada{HTTP/1.1, (http/1.1)}{ip-172-31-39-172.ec2.internal:9870}
2026-01-22 00:55:50,164 INFO org.eclipse.jetty.server.Server (main): Started @2457ms
2026-01-22 00:55:50,307 INFO org.apache.hadoop.hdfs.server.common.Util (main): Assuming 'file' scheme for path /mnt/namenode in configuration.
2026-01-22 00:55:50,308 INFO org.apache.hadoop.hdfs.server.common.Util (main): Assuming 'file' scheme for path /mnt1/namenode in configuration.
2026-01-22 00:55:50,308 INFO org.apache.hadoop.hdfs.server.common.Util (main): Assuming 'file' scheme for path /mnt/namenode in configuration.
2026-01-22 00:55:50,308 INFO org.apache.hadoop.hdfs.server.common.Util (main): Assuming 'file' scheme for path /mnt1/namenode in configuration.
2026-01-22 00:55:50,326 INFO org.apache.hadoop.hdfs.server.common.Util (main): Assuming 'file' scheme for path /mnt/namenode in configuration.
2026-01-22 00:55:50,326 INFO org.apache.hadoop.hdfs.server.common.Util (main): Assuming 'file' scheme for path /mnt1/namenode in configuration.
2026-01-22 00:55:50,326 INFO org.apache.hadoop.hdfs.server.common.Util (main): Assuming 'file' scheme for path /mnt/namenode in configuration.
2026-01-22 00:55:50,326 INFO org.apache.hadoop.hdfs.server.common.Util (main): Assuming 'file' scheme for path /mnt1/namenode in configuration.
2026-01-22 00:55:50,379 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog (main): Edit logging is async:true
2026-01-22 00:55:50,859 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem (main): KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@4f82663e
2026-01-22 00:55:50,861 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem (main): fsLock is fair: true
2026-01-22 00:55:50,861 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem (main): Detailed lock hold time metrics enabled: false
2026-01-22 00:55:50,926 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem (main): fsOwner                = hdfs (auth:SIMPLE)
2026-01-22 00:55:50,927 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem (main): supergroup             = hdfsadmingroup
2026-01-22 00:55:50,927 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem (main): isPermissionEnabled    = true
2026-01-22 00:55:50,927 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem (main): isStoragePolicyEnabled = true
2026-01-22 00:55:50,929 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem (main): HA Enabled: false
2026-01-22 00:55:51,041 INFO org.apache.hadoop.hdfs.server.common.Util (main): dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2026-01-22 00:55:51,588 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager (main): Slow peers collection thread shutdown
2026-01-22 00:55:51,634 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager (main): dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2026-01-22 00:55:51,634 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager (main): dfs.namenode.datanode.registration.ip-hostname-check=true
2026-01-22 00:55:51,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (main): dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2026-01-22 00:55:51,659 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (main): The block deletion will start around 2026 Jan 22 00:55:51
2026-01-22 00:55:51,660 INFO org.apache.hadoop.util.GSet (main): Computing capacity for map BlocksMap
2026-01-22 00:55:51,660 INFO org.apache.hadoop.util.GSet (main): VM type       = 64-bit
2026-01-22 00:55:51,678 INFO org.apache.hadoop.util.GSet (main): 2.0% max memory 1.8 GB = 36.9 MB
2026-01-22 00:55:51,678 INFO org.apache.hadoop.util.GSet (main): capacity      = 2^22 = 4194304 entries
2026-01-22 00:55:51,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (main): Storage policy satisfier is disabled
2026-01-22 00:55:51,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (main): dfs.block.access.token.enable = false
2026-01-22 00:55:51,800 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode (main): Using 1000 as SafeModeMonitor Interval
2026-01-22 00:55:51,800 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode (main): dfs.namenode.safemode.threshold-pct = 0.999
2026-01-22 00:55:51,800 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode (main): dfs.namenode.safemode.min.datanodes = 0
2026-01-22 00:55:51,800 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode (main): dfs.namenode.safemode.extension = 5000
2026-01-22 00:55:51,801 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (main): defaultReplication         = 2
2026-01-22 00:55:51,801 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (main): maxReplication             = 512
2026-01-22 00:55:51,801 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (main): minReplication             = 1
2026-01-22 00:55:51,801 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (main): maxReplicationStreams      = 100
2026-01-22 00:55:51,801 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (main): redundancyRecheckInterval  = 3000ms
2026-01-22 00:55:51,801 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (main): encryptDataTransfer        = false
2026-01-22 00:55:51,801 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (main): maxNumBlocksToLog          = 1000
2026-01-22 00:55:51,923 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory (main): GLOBAL serial map: bits=29 maxEntries=536870911
2026-01-22 00:55:51,923 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory (main): USER serial map: bits=24 maxEntries=16777215
2026-01-22 00:55:51,923 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory (main): GROUP serial map: bits=24 maxEntries=16777215
2026-01-22 00:55:51,923 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory (main): XATTR serial map: bits=24 maxEntries=16777215
2026-01-22 00:55:51,971 INFO org.apache.hadoop.util.GSet (main): Computing capacity for map INodeMap
2026-01-22 00:55:51,971 INFO org.apache.hadoop.util.GSet (main): VM type       = 64-bit
2026-01-22 00:55:51,974 INFO org.apache.hadoop.util.GSet (main): 1.0% max memory 1.8 GB = 18.4 MB
2026-01-22 00:55:51,974 INFO org.apache.hadoop.util.GSet (main): capacity      = 2^21 = 2097152 entries
2026-01-22 00:55:51,999 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory (main): ACLs enabled? true
2026-01-22 00:55:52,000 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory (main): POSIX ACL inheritance enabled? true
2026-01-22 00:55:52,000 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory (main): XAttrs enabled? true
2026-01-22 00:55:52,000 INFO org.apache.hadoop.hdfs.server.namenode.NameNode (main): Caching file names occurring more than 10 times
2026-01-22 00:55:52,005 INFO org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler (main): Configured throttleLimitHandlerRatio=1.0 for re-encryption
2026-01-22 00:55:52,013 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager (main): Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2026-01-22 00:55:52,013 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager (main): dfs.namenode.snapshot.deletion.ordered = false
2026-01-22 00:55:52,017 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager (main): SkipList is disabled
2026-01-22 00:55:52,022 INFO org.apache.hadoop.util.GSet (main): Computing capacity for map cachedBlocks
2026-01-22 00:55:52,022 INFO org.apache.hadoop.util.GSet (main): VM type       = 64-bit
2026-01-22 00:55:52,023 INFO org.apache.hadoop.util.GSet (main): 0.25% max memory 1.8 GB = 4.6 MB
2026-01-22 00:55:52,023 INFO org.apache.hadoop.util.GSet (main): capacity      = 2^19 = 524288 entries
2026-01-22 00:55:52,063 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics (main): NNTop conf: dfs.namenode.top.window.num.buckets = 10
2026-01-22 00:55:52,063 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics (main): NNTop conf: dfs.namenode.top.num.users = 10
2026-01-22 00:55:52,063 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics (main): NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2026-01-22 00:55:52,125 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem (main): Retry cache on namenode is enabled
2026-01-22 00:55:52,125 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem (main): Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2026-01-22 00:55:52,127 INFO org.apache.hadoop.util.GSet (main): Computing capacity for map NameNodeRetryCache
2026-01-22 00:55:52,127 INFO org.apache.hadoop.util.GSet (main): VM type       = 64-bit
2026-01-22 00:55:52,130 INFO org.apache.hadoop.util.GSet (main): 0.029999999329447746% max memory 1.8 GB = 566.5 KB
2026-01-22 00:55:52,130 INFO org.apache.hadoop.util.GSet (main): capacity      = 2^16 = 65536 entries
2026-01-22 00:55:52,145 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem (main): Removal of  Expired Lease on Open Files is enabled
2026-01-22 00:55:52,214 INFO org.apache.hadoop.hdfs.server.common.Storage (main): Lock on /mnt/namenode/in_use.lock acquired by nodename 8923@ip-172-31-39-172.ec2.internal
2026-01-22 00:55:52,234 INFO org.apache.hadoop.hdfs.server.common.Storage (main): Lock on /mnt1/namenode/in_use.lock acquired by nodename 8923@ip-172-31-39-172.ec2.internal
2026-01-22 00:55:52,277 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager (main): Recovering unfinalized segments in /mnt/namenode/current
2026-01-22 00:55:52,278 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager (main): Recovering unfinalized segments in /mnt1/namenode/current
2026-01-22 00:55:52,278 INFO org.apache.hadoop.hdfs.server.namenode.FSImage (main): No edit log streams selected.
2026-01-22 00:55:52,278 INFO org.apache.hadoop.hdfs.server.namenode.FSImage (main): Planning to load image: FSImageFile(file=/mnt/namenode/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2026-01-22 00:55:52,433 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode (main): Loading 1 INodes.
2026-01-22 00:55:52,480 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode (main): Successfully loaded 1 inodes
2026-01-22 00:55:52,515 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode (main): Completed update blocks map and name cache, total waiting duration 0ms.
2026-01-22 00:55:52,535 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf (main): Loaded FSImage in 0 seconds.
2026-01-22 00:55:52,535 INFO org.apache.hadoop.hdfs.server.namenode.FSImage (main): Loaded image for txid 0 from /mnt/namenode/current/fsimage_0000000000000000000
2026-01-22 00:55:52,541 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem (main): Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2026-01-22 00:55:52,550 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog (main): Starting log segment at 1
2026-01-22 00:55:52,762 INFO org.apache.hadoop.hdfs.server.namenode.NameCache (main): initialized with 0 entries 0 lookups
2026-01-22 00:55:52,762 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem (main): Finished loading FSImage in 617 msecs
2026-01-22 00:55:53,235 INFO org.apache.hadoop.hdfs.server.namenode.NameNode (main): RPC server is binding to ip-172-31-39-172.ec2.internal:8020
2026-01-22 00:55:53,235 INFO org.apache.hadoop.hdfs.server.namenode.NameNode (main): Enable NameNode state context:false
2026-01-22 00:55:53,244 INFO org.apache.hadoop.ipc.CallQueueManager (main): Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 6400, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2026-01-22 00:55:53,281 INFO org.apache.hadoop.ipc.Server (main): Listener at ip-172-31-39-172.ec2.internal:8020
2026-01-22 00:55:53,282 INFO org.apache.hadoop.ipc.Server (Socket Reader #1 for port 8020): Starting Socket Reader #1 for port 8020
2026-01-22 00:55:53,473 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem (main): Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2026-01-22 00:55:53,474 INFO org.apache.hadoop.hdfs.server.common.Util (main): Assuming 'file' scheme for path /mnt/namenode in configuration.
2026-01-22 00:55:53,475 INFO org.apache.hadoop.hdfs.server.common.Util (main): Assuming 'file' scheme for path /mnt1/namenode in configuration.
2026-01-22 00:55:53,547 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager (main): Number of blocks under construction: 0
2026-01-22 00:55:53,561 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminDefaultMonitor (main): Initialized the Default Decommission and Maintenance monitor
2026-01-22 00:55:53,604 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (MarkedDeleteBlockScrubberThread): Start MarkedDeleteBlockScrubber thread
2026-01-22 00:55:53,607 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (main): initializing replication queues
2026-01-22 00:55:53,608 INFO org.apache.hadoop.hdfs.StateChange (main): STATE* Leaving safe mode after 0 secs
2026-01-22 00:55:53,608 INFO org.apache.hadoop.hdfs.StateChange (main): STATE* Network topology has 0 racks and 0 datanodes
2026-01-22 00:55:53,608 INFO org.apache.hadoop.hdfs.StateChange (main): STATE* UnderReplicatedBlocks has 0 blocks
2026-01-22 00:55:53,657 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (Reconstruction Queue Initializer): Total number of blocks            = 0
2026-01-22 00:55:53,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (Reconstruction Queue Initializer): Number of invalid blocks          = 0
2026-01-22 00:55:53,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (Reconstruction Queue Initializer): Number of under-replicated blocks = 0
2026-01-22 00:55:53,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (Reconstruction Queue Initializer): Number of  over-replicated blocks = 0
2026-01-22 00:55:53,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (Reconstruction Queue Initializer): Number of blocks being written    = 0
2026-01-22 00:55:53,658 INFO org.apache.hadoop.hdfs.StateChange (Reconstruction Queue Initializer): STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 21 msec
2026-01-22 00:55:53,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager (Reconstruction Queue Initializer): Reconstruction queues initialisation progress: 0.0, total number of blocks processed: 0/0
2026-01-22 00:55:53,705 INFO org.apache.hadoop.ipc.Server (IPC Server Responder): IPC Server Responder: starting
2026-01-22 00:55:53,707 INFO org.apache.hadoop.ipc.Server (IPC Server listener on 8020): IPC Server listener on 8020: starting
2026-01-22 00:55:53,764 INFO org.apache.hadoop.hdfs.server.namenode.NameNode (main): NameNode RPC up at: ip-172-31-39-172.ec2.internal/172.31.39.172:8020.
2026-01-22 00:55:53,769 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem (main): Starting services required for active state
2026-01-22 00:55:53,769 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory (main): Initializing quota with 12 thread(s)
2026-01-22 00:55:53,777 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory (main): Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0, NVDIMM=0
2026-01-22 00:55:53,779 INFO org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler (reencryptionHandlerThread #0): Starting up re-encrypt thread with interval=60000 millisecond.
2026-01-22 00:55:53,846 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor(1166083398)): Starting CacheReplicationMonitor with interval 30000 milliseconds
2026-01-22 00:55:53,922 INFO org.apache.hadoop.hdfs.server.namenode.NameNode (Warm Up EDEK Cache Thread #0): Warming up 0 EDEKs... (initialDelay=3000, retryInterval=1000)
2026-01-22 00:55:54,372 INFO org.apache.hadoop.hdfs.StateChange (IPC Server handler 8 on default port 8020): BLOCK* registerDatanode: from DatanodeRegistration(172.31.42.110:9866, datanodeUuid=be7939bd-8497-424c-b956-e7ee21ac6b7a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926) storage be7939bd-8497-424c-b956-e7ee21ac6b7a
2026-01-22 00:55:54,373 INFO org.apache.hadoop.net.NetworkTopology (IPC Server handler 8 on default port 8020): Adding a new node: /default-rack/172.31.42.110:9866
2026-01-22 00:55:54,374 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager (IPC Server handler 8 on default port 8020): Registered DN be7939bd-8497-424c-b956-e7ee21ac6b7a (172.31.42.110:9866).
2026-01-22 00:55:54,381 INFO org.apache.hadoop.hdfs.StateChange (IPC Server handler 6 on default port 8020): BLOCK* registerDatanode: from DatanodeRegistration(172.31.44.229:9866, datanodeUuid=9d677f48-c1c8-460a-abc2-dcaa14bf1ee2, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926) storage 9d677f48-c1c8-460a-abc2-dcaa14bf1ee2
2026-01-22 00:55:54,381 INFO org.apache.hadoop.net.NetworkTopology (IPC Server handler 6 on default port 8020): Adding a new node: /default-rack/172.31.44.229:9866
2026-01-22 00:55:54,381 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager (IPC Server handler 6 on default port 8020): Registered DN 9d677f48-c1c8-460a-abc2-dcaa14bf1ee2 (172.31.44.229:9866).
2026-01-22 00:55:54,395 INFO org.apache.hadoop.hdfs.StateChange (IPC Server handler 9 on default port 8020): BLOCK* registerDatanode: from DatanodeRegistration(172.31.32.145:9866, datanodeUuid=1272bebc-973c-480f-9bd9-17af4776abfd, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926) storage 1272bebc-973c-480f-9bd9-17af4776abfd
2026-01-22 00:55:54,395 INFO org.apache.hadoop.net.NetworkTopology (IPC Server handler 9 on default port 8020): Adding a new node: /default-rack/172.31.32.145:9866
2026-01-22 00:55:54,395 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager (IPC Server handler 9 on default port 8020): Registered DN 1272bebc-973c-480f-9bd9-17af4776abfd (172.31.32.145:9866).
2026-01-22 00:55:54,419 INFO org.apache.hadoop.hdfs.StateChange (IPC Server handler 7 on default port 8020): BLOCK* registerDatanode: from DatanodeRegistration(172.31.37.64:9866, datanodeUuid=d58943f7-1dca-4a54-8098-7495824d4a79, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926) storage d58943f7-1dca-4a54-8098-7495824d4a79
2026-01-22 00:55:54,419 INFO org.apache.hadoop.net.NetworkTopology (IPC Server handler 7 on default port 8020): Adding a new node: /default-rack/172.31.37.64:9866
2026-01-22 00:55:54,419 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager (IPC Server handler 7 on default port 8020): Registered DN d58943f7-1dca-4a54-8098-7495824d4a79 (172.31.37.64:9866).
2026-01-22 00:55:54,432 INFO org.apache.hadoop.hdfs.StateChange (IPC Server handler 5 on default port 8020): BLOCK* registerDatanode: from DatanodeRegistration(172.31.32.195:9866, datanodeUuid=70f1e382-af45-4b15-82ef-3117f6a50e34, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926) storage 70f1e382-af45-4b15-82ef-3117f6a50e34
2026-01-22 00:55:54,433 INFO org.apache.hadoop.net.NetworkTopology (IPC Server handler 5 on default port 8020): Adding a new node: /default-rack/172.31.32.195:9866
2026-01-22 00:55:54,433 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager (IPC Server handler 5 on default port 8020): Registered DN 70f1e382-af45-4b15-82ef-3117f6a50e34 (172.31.32.195:9866).
2026-01-22 00:55:54,488 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor (IPC Server handler 12 on default port 8020): Adding new storage ID DS-5f7c1582-d06e-4f84-8c67-87418acb9d88 for DN 172.31.32.145:9866
2026-01-22 00:55:54,488 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor (IPC Server handler 12 on default port 8020): Adding new storage ID DS-25a9191f-674b-4704-83a3-ac83998a131d for DN 172.31.32.145:9866
2026-01-22 00:55:54,489 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor (IPC Server handler 10 on default port 8020): Adding new storage ID DS-6e336144-0f2a-4c80-b3d5-34eeecc8fead for DN 172.31.44.229:9866
2026-01-22 00:55:54,489 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor (IPC Server handler 10 on default port 8020): Adding new storage ID DS-27a63484-d1cb-4703-97fc-e655292facd8 for DN 172.31.44.229:9866
2026-01-22 00:55:54,489 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor (IPC Server handler 11 on default port 8020): Adding new storage ID DS-4bc905d2-c11c-4ba4-838b-60fcb8d5eab4 for DN 172.31.42.110:9866
2026-01-22 00:55:54,489 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor (IPC Server handler 11 on default port 8020): Adding new storage ID DS-bfd93ab9-e10e-4de1-ab4d-2fe3848c7c70 for DN 172.31.42.110:9866
2026-01-22 00:55:54,489 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor (IPC Server handler 13 on default port 8020): Adding new storage ID DS-fa00518d-5047-4675-83d5-82a11d31869a for DN 172.31.37.64:9866
2026-01-22 00:55:54,489 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor (IPC Server handler 13 on default port 8020): Adding new storage ID DS-751f5e59-f367-4fd0-9d0a-4eda9fbf85a9 for DN 172.31.37.64:9866
2026-01-22 00:55:54,489 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor (IPC Server handler 14 on default port 8020): Adding new storage ID DS-c9e21c42-9806-4630-9982-23ffdf997f96 for DN 172.31.32.195:9866
2026-01-22 00:55:54,489 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor (IPC Server handler 14 on default port 8020): Adding new storage ID DS-a1d48bd0-816f-431e-8b60-bdca5ac0dae4 for DN 172.31.32.195:9866
2026-01-22 00:55:54,550 INFO BlockStateChange (Block report processor): BLOCK* processReport 0x125b9a83fb2c4d0c with lease ID 0xb1bfdb3b0929d482: Processing first storage report for DS-4bc905d2-c11c-4ba4-838b-60fcb8d5eab4 from datanode DatanodeRegistration(172.31.42.110:9866, datanodeUuid=be7939bd-8497-424c-b956-e7ee21ac6b7a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926)
2026-01-22 00:55:54,551 INFO BlockStateChange (Block report processor): BLOCK* processReport 0x125b9a83fb2c4d0c with lease ID 0xb1bfdb3b0929d482: from storage DS-4bc905d2-c11c-4ba4-838b-60fcb8d5eab4 node DatanodeRegistration(172.31.42.110:9866, datanodeUuid=be7939bd-8497-424c-b956-e7ee21ac6b7a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2026-01-22 00:55:54,551 INFO BlockStateChange (Block report processor): BLOCK* processReport 0x13722cff8211be27 with lease ID 0xb1bfdb3b0929d483: Processing first storage report for DS-fa00518d-5047-4675-83d5-82a11d31869a from datanode DatanodeRegistration(172.31.37.64:9866, datanodeUuid=d58943f7-1dca-4a54-8098-7495824d4a79, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926)
2026-01-22 00:55:54,551 INFO BlockStateChange (Block report processor): BLOCK* processReport 0x13722cff8211be27 with lease ID 0xb1bfdb3b0929d483: from storage DS-fa00518d-5047-4675-83d5-82a11d31869a node DatanodeRegistration(172.31.37.64:9866, datanodeUuid=d58943f7-1dca-4a54-8098-7495824d4a79, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2026-01-22 00:55:54,554 INFO BlockStateChange (Block report processor): BLOCK* processReport 0xc061c0e8c603810e with lease ID 0xb1bfdb3b0929d481: Processing first storage report for DS-25a9191f-674b-4704-83a3-ac83998a131d from datanode DatanodeRegistration(172.31.32.145:9866, datanodeUuid=1272bebc-973c-480f-9bd9-17af4776abfd, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926)
2026-01-22 00:55:54,554 INFO BlockStateChange (Block report processor): BLOCK* processReport 0xc061c0e8c603810e with lease ID 0xb1bfdb3b0929d481: from storage DS-25a9191f-674b-4704-83a3-ac83998a131d node DatanodeRegistration(172.31.32.145:9866, datanodeUuid=1272bebc-973c-480f-9bd9-17af4776abfd, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2026-01-22 00:55:54,554 INFO BlockStateChange (Block report processor): BLOCK* processReport 0x43d3b12219b598e3 with lease ID 0xb1bfdb3b0929d485: Processing first storage report for DS-6e336144-0f2a-4c80-b3d5-34eeecc8fead from datanode DatanodeRegistration(172.31.44.229:9866, datanodeUuid=9d677f48-c1c8-460a-abc2-dcaa14bf1ee2, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926)
2026-01-22 00:55:54,554 INFO BlockStateChange (Block report processor): BLOCK* processReport 0x43d3b12219b598e3 with lease ID 0xb1bfdb3b0929d485: from storage DS-6e336144-0f2a-4c80-b3d5-34eeecc8fead node DatanodeRegistration(172.31.44.229:9866, datanodeUuid=9d677f48-c1c8-460a-abc2-dcaa14bf1ee2, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2026-01-22 00:55:54,554 INFO BlockStateChange (Block report processor): BLOCK* processReport 0xb75b6a98060f7851 with lease ID 0xb1bfdb3b0929d484: Processing first storage report for DS-a1d48bd0-816f-431e-8b60-bdca5ac0dae4 from datanode DatanodeRegistration(172.31.32.195:9866, datanodeUuid=70f1e382-af45-4b15-82ef-3117f6a50e34, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926)
2026-01-22 00:55:54,554 INFO BlockStateChange (Block report processor): BLOCK* processReport 0xb75b6a98060f7851 with lease ID 0xb1bfdb3b0929d484: from storage DS-a1d48bd0-816f-431e-8b60-bdca5ac0dae4 node DatanodeRegistration(172.31.32.195:9866, datanodeUuid=70f1e382-af45-4b15-82ef-3117f6a50e34, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2026-01-22 00:55:54,555 INFO BlockStateChange (Block report processor): BLOCK* processReport 0x125b9a83fb2c4d0c with lease ID 0xb1bfdb3b0929d482: Processing first storage report for DS-bfd93ab9-e10e-4de1-ab4d-2fe3848c7c70 from datanode DatanodeRegistration(172.31.42.110:9866, datanodeUuid=be7939bd-8497-424c-b956-e7ee21ac6b7a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926)
2026-01-22 00:55:54,555 INFO BlockStateChange (Block report processor): BLOCK* processReport 0x125b9a83fb2c4d0c with lease ID 0xb1bfdb3b0929d482: from storage DS-bfd93ab9-e10e-4de1-ab4d-2fe3848c7c70 node DatanodeRegistration(172.31.42.110:9866, datanodeUuid=be7939bd-8497-424c-b956-e7ee21ac6b7a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2026-01-22 00:55:54,555 INFO BlockStateChange (Block report processor): BLOCK* processReport 0x13722cff8211be27 with lease ID 0xb1bfdb3b0929d483: Processing first storage report for DS-751f5e59-f367-4fd0-9d0a-4eda9fbf85a9 from datanode DatanodeRegistration(172.31.37.64:9866, datanodeUuid=d58943f7-1dca-4a54-8098-7495824d4a79, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926)
2026-01-22 00:55:54,555 INFO BlockStateChange (Block report processor): BLOCK* processReport 0x13722cff8211be27 with lease ID 0xb1bfdb3b0929d483: from storage DS-751f5e59-f367-4fd0-9d0a-4eda9fbf85a9 node DatanodeRegistration(172.31.37.64:9866, datanodeUuid=d58943f7-1dca-4a54-8098-7495824d4a79, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2026-01-22 00:55:54,564 INFO BlockStateChange (Block report processor): BLOCK* processReport 0xc061c0e8c603810e with lease ID 0xb1bfdb3b0929d481: Processing first storage report for DS-5f7c1582-d06e-4f84-8c67-87418acb9d88 from datanode DatanodeRegistration(172.31.32.145:9866, datanodeUuid=1272bebc-973c-480f-9bd9-17af4776abfd, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926)
2026-01-22 00:55:54,564 INFO BlockStateChange (Block report processor): BLOCK* processReport 0xc061c0e8c603810e with lease ID 0xb1bfdb3b0929d481: from storage DS-5f7c1582-d06e-4f84-8c67-87418acb9d88 node DatanodeRegistration(172.31.32.145:9866, datanodeUuid=1272bebc-973c-480f-9bd9-17af4776abfd, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2026-01-22 00:55:54,564 INFO BlockStateChange (Block report processor): BLOCK* processReport 0xb75b6a98060f7851 with lease ID 0xb1bfdb3b0929d484: Processing first storage report for DS-c9e21c42-9806-4630-9982-23ffdf997f96 from datanode DatanodeRegistration(172.31.32.195:9866, datanodeUuid=70f1e382-af45-4b15-82ef-3117f6a50e34, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926)
2026-01-22 00:55:54,564 INFO BlockStateChange (Block report processor): BLOCK* processReport 0xb75b6a98060f7851 with lease ID 0xb1bfdb3b0929d484: from storage DS-c9e21c42-9806-4630-9982-23ffdf997f96 node DatanodeRegistration(172.31.32.195:9866, datanodeUuid=70f1e382-af45-4b15-82ef-3117f6a50e34, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2026-01-22 00:55:54,564 INFO BlockStateChange (Block report processor): BLOCK* processReport 0x43d3b12219b598e3 with lease ID 0xb1bfdb3b0929d485: Processing first storage report for DS-27a63484-d1cb-4703-97fc-e655292facd8 from datanode DatanodeRegistration(172.31.44.229:9866, datanodeUuid=9d677f48-c1c8-460a-abc2-dcaa14bf1ee2, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926)
2026-01-22 00:55:54,564 INFO BlockStateChange (Block report processor): BLOCK* processReport 0x43d3b12219b598e3 with lease ID 0xb1bfdb3b0929d485: from storage DS-27a63484-d1cb-4703-97fc-e655292facd8 node DatanodeRegistration(172.31.44.229:9866, datanodeUuid=9d677f48-c1c8-460a-abc2-dcaa14bf1ee2, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a79cd4e2-82d5-441d-b9fa-443a1ec9167d;nsid=9694206;c=1769043346926), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2026-01-22 00:55:55,054 INFO org.apache.hadoop.metrics2.lib.Interns (IPC Server handler 3 on default port 8020): Metrics intern cache overflow at 2011 for MetricsSystem={MetricsSystem=MetricsInfoImpl{name=MetricsSystem, description=MetricsSystem}, MetricsSystem record=MetricsInfoImpl{name=MetricsSystem, description=MetricsSystem record}}
2026-01-22 00:55:56,923 INFO org.apache.hadoop.hdfs.server.namenode.NameNode (Warm Up EDEK Cache Thread #0): Successfully warmed up 0 EDEKs.
2026-01-22 00:58:27,472 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog (FSEditLogAsync): Number of transactions: 42 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 0 Number of syncs: 42 SyncTimes(ms): 31 25 
2026-01-22 00:58:27,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy (IPC Server handler 46 on default port 8020): Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2026-01-22 00:58:27,737 INFO org.apache.hadoop.hdfs.StateChange (IPC Server handler 46 on default port 8020): BLOCK* allocate blk_1073741825_1001, replicas=172.31.32.145:9866, 172.31.37.64:9866 for /tmp/hadoop-yarn/staging/hadoop/.staging/job_1769043374276_0001/job.jar
2026-01-22 00:58:28,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem (IPC Server handler 2 on default port 8020): BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/hadoop/.staging/job_1769043374276_0001/job.jar
2026-01-22 00:58:28,040 INFO BlockStateChange (Block report processor): BLOCK* addStoredBlock: 172.31.32.145:9866 is added to blk_1073741825_1001 (size=54223)
2026-01-22 00:58:28,041 INFO BlockStateChange (Block report processor): BLOCK* addStoredBlock: 172.31.37.64:9866 is added to blk_1073741825_1001 (size=54223)
2026-01-22 00:58:28,432 INFO org.apache.hadoop.hdfs.StateChange (IPC Server handler 39 on default port 8020): DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop/.staging/job_1769043374276_0001/job.jar is closed by DFSClient_NONMAPREDUCE_-1922568836_1
