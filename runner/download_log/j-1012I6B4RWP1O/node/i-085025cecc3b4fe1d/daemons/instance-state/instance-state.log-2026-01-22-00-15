OS is AL2023: /usr/bin/ruby
Sleeping for a random period of time up to 10 minutes
Sleeping for 146.0212693990924 seconds
Thu Jan 22 00:17:28 UTC 2026

# how long have we been up
uptime
 00:17:28 up 11 min,  0 users,  load average: 2.48, 3.17, 1.77

# whats running, with ASCII-art process hierarchy (forest)
if [ "$dumpType" == "full" ]
then
  ps auxwwwf
else
  ps auxf --width=200
fi
USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root           2  0.0  0.0      0     0 ?        S    00:05   0:00 [kthreadd]
root           3  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [rcu_gp]
root           4  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [rcu_par_gp]
root           5  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [slub_flushwq]
root           6  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [netns]
root           7  0.0  0.0      0     0 ?        I    00:05   0:00  \_ [kworker/0:0-mm_percpu_wq]
root           8  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [kworker/0:0H-events_highpri]
root          10  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [mm_percpu_wq]
root          11  0.0  0.0      0     0 ?        I    00:05   0:00  \_ [rcu_tasks_kthread]
root          12  0.0  0.0      0     0 ?        I    00:05   0:00  \_ [rcu_tasks_rude_kthread]
root          13  0.0  0.0      0     0 ?        I    00:05   0:00  \_ [rcu_tasks_trace_kthread]
root          14  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [ksoftirqd/0]
root          15  0.0  0.0      0     0 ?        I    00:05   0:00  \_ [rcu_preempt]
root          16  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [migration/0]
root          17  0.0  0.0      0     0 ?        I    00:05   0:00  \_ [kworker/0:1-events]
root          18  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [cpuhp/0]
root          19  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [cpuhp/1]
root          20  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [migration/1]
root          21  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [ksoftirqd/1]
root          22  0.0  0.0      0     0 ?        I    00:05   0:00  \_ [kworker/1:0-cgroup_release]
root          23  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [kworker/1:0H-events_highpri]
root          24  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [cpuhp/2]
root          25  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [migration/2]
root          26  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [ksoftirqd/2]
root          28  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [kworker/2:0H-events_highpri]
root          29  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [cpuhp/3]
root          30  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [migration/3]
root          31  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [ksoftirqd/3]
root          32  0.0  0.0      0     0 ?        I    00:05   0:00  \_ [kworker/3:0-cgroup_release]
root          33  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [kworker/3:0H-events_highpri]
root          37  0.0  0.0      0     0 ?        I    00:05   0:00  \_ [kworker/u8:3-events_unbound]
root          38  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [kdevtmpfs]
root          39  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [inet_frag_wq]
root          40  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [kauditd]
root          41  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [khungtaskd]
root          42  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [oom_reaper]
root          43  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [writeback]
root          44  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [kcompactd0]
root          46  0.0  0.0      0     0 ?        SN   00:05   0:00  \_ [khugepaged]
root          47  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [cryptd]
root          48  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [kintegrityd]
root          49  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [kblockd]
root          50  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [blkcg_punt_bio]
root          51  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [tpm_dev_wq]
root          52  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [md]
root          53  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [edac-poller]
root          54  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [watchdogd]
root          55  0.0  0.0      0     0 ?        I    00:05   0:00  \_ [kworker/2:1-events]
root          57  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [kworker/2:1H-xfs-log/nvme1n1p1]
root          85  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [kswapd0]
root          88  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfsalloc]
root          89  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs_mru_cache]
root          92  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [kthrotld]
root          95  0.0  0.0      0     0 ?        I    00:05   0:00  \_ [kworker/3:1-cgroup_release]
root         144  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [nvme-wq]
root         146  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [nvme-reset-wq]
root         148  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [nvme-delete-wq]
root         154  0.0  0.0      0     0 ?        I    00:05   0:00  \_ [kworker/u8:4-writeback]
root         161  0.0  0.0      0     0 ?        I    00:05   0:00  \_ [kworker/u8:7-events_unbound]
root         203  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [mld]
root         204  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [ipv6_addrconf]
root         205  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [kworker/3:1H-xfs-log/nvme1n1p1]
root         215  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [kstrp]
root         227  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [zswap-shrink]
root         228  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [kworker/u9:0]
root         328  0.0  0.0      0     0 ?        I    00:05   0:00  \_ [kworker/1:2-cgroup_bpf_destroy]
root         345  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [kworker/1:1H-kblockd]
root         351  0.0  0.0      0     0 ?        I    00:05   0:00  \_ [kworker/0:2-events]
root         387  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [kworker/0:1H-kblockd]
root         960  0.0  0.0      0     0 ?        I    00:05   0:00  \_ [kworker/2:2-cgroup_offline]
root         985  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-buf/nvme0n1]
root         987  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-conv/nvme0n]
root         988  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-reclaim/nvm]
root         990  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-blockgc/nvm]
root         991  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-inodegc/nvm]
root         992  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-log/nvme0n1]
root         993  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-cil/nvme0n1]
root         994  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [xfsaild/nvme0n1p1]
root        1612  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [rpciod]
root        1613  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xprtiod]
root        1619  0.0  0.0      0     0 ?        I    00:05   0:00  \_ [kworker/2:3-rcu_gp]
root        1719  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [ena]
root        2335  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-buf/nvme1n1]
root        2336  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-conv/nvme1n]
root        2337  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-reclaim/nvm]
root        2338  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-blockgc/nvm]
root        2339  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-inodegc/nvm]
root        2342  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-log/nvme1n1]
root        2343  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-cil/nvme1n1]
root        2344  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [xfsaild/nvme1n1p1]
root        2417  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-buf/nvme1n1]
root        2418  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-conv/nvme1n]
root        2419  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-reclaim/nvm]
root        2420  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-blockgc/nvm]
root        2421  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-inodegc/nvm]
root        2425  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-log/nvme1n1]
root        2426  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-cil/nvme1n1]
root        2427  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [xfsaild/nvme1n1p2]
root        2517  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-buf/nvme2n1]
root        2518  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-conv/nvme2n]
root        2519  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-reclaim/nvm]
root        2520  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-blockgc/nvm]
root        2521  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-inodegc/nvm]
root        2524  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-log/nvme2n1]
root        2525  0.0  0.0      0     0 ?        I<   00:05   0:00  \_ [xfs-cil/nvme2n1]
root        2526  0.0  0.0      0     0 ?        S    00:05   0:00  \_ [xfsaild/nvme2n1]
root        3845  0.0  0.0      0     0 ?        I    00:06   0:00  \_ [kworker/1:3-cgroup_release]
root        5234  0.0  0.0      0     0 ?        I    00:07   0:00  \_ [kworker/3:3-xfs-inodegc/nvme1n1p2]
root        7821  0.0  0.0      0     0 ?        I    00:11   0:00  \_ [kworker/1:1-xfs-inodegc/nvme1n1p2]
root        7889  0.0  0.0      0     0 ?        I    00:12   0:00  \_ [kworker/2:0-events]
root        8356  0.0  0.0      0     0 ?        I    00:14   0:00  \_ [kworker/3:2-cgroup_bpf_destroy]
root        8597  0.0  0.0      0     0 ?        I    00:14   0:00  \_ [kworker/u8:0-writeback]
root        8792  0.0  0.0      0     0 ?        I    00:15   0:00  \_ [kworker/1:4-events]
root        9032  0.0  0.0      0     0 ?        I    00:15   0:00  \_ [kworker/0:3]
root        9618  0.0  0.0      0     0 ?        I    00:17   0:00  \_ [kworker/3:4-events]
root           1  0.7  0.1 172968 17964 ?        Ss   00:05   0:05 /usr/lib/systemd/systemd --switched-root --system --deserialize=32
root        1039  0.1  0.1  54092 18828 ?        Ss   00:05   0:00 /usr/lib/systemd/systemd-journald
systemd+    1610  0.0  0.0  22600 15004 ?        Ss   00:05   0:00 /usr/lib/systemd/systemd-resolved
root        1611  0.0  0.0  32028 11604 ?        Ss   00:05   0:00 /usr/lib/systemd/systemd-udevd
root        1615  0.0  0.0  21184  2220 ?        S<sl 00:05   0:00 /sbin/auditd
dbus        1788  0.0  0.0   8500  4152 ?        Ss   00:05   0:00 /usr/bin/dbus-broker-launch --scope system --audit
dbus        1789  0.0  0.0   5512  3072 ?        S    00:05   0:00  \_ dbus-broker --log 4 --controller 9 --machine-id ec276fc410ae8f3bf6c5605dc1bcdbc7 --max-bytes 536870912 --max-fds 4096 --max-matches 16384 --audit
root        1790  0.0  0.0  16352  6376 ?        Ss   00:05   0:00 /usr/bin/systemd-inhibit --what=handle-suspend-key:handle-hibernate-key --who=noah --why=acpid instead --mode=block /usr/sbin/acpid -f
root        1831  0.0  0.0   2684  1132 ?        S    00:05   0:00  \_ /usr/sbin/acpid -f
root        1793  0.0  0.0  81420  1572 ?        Ssl  00:05   0:00 /usr/sbin/irqbalance --foreground
libstor+    1794  0.0  0.0   2772  1980 ?        Ss   00:05   0:00 /usr/bin/lsmd -d
rtkit       1797  0.0  0.0 155932  2648 ?        SNsl 00:05   0:00 /usr/libexec/rtkit-daemon
root        1802  0.0  0.0  16872  8040 ?        Ss   00:05   0:00 /usr/lib/systemd/systemd-homed
root        1804  0.0  0.0  19136 11088 ?        Ss   00:05   0:00 /usr/lib/systemd/systemd-logind
root        1806  0.0  0.0 531916  6528 ?        Ssl  00:05   0:00 /usr/libexec/upowerd
systemd+    1846  0.0  0.0 236948  9940 ?        Ss   00:05   0:00 /usr/lib/systemd/systemd-networkd
polkitd     1848  0.0  0.0 314204  7324 ?        Ssl  00:05   0:00 /usr/lib/polkit-1/polkitd --no-debug --log-level=err
root        1906  0.0  0.0 281944  3740 ?        Ssl  00:05   0:00 /usr/sbin/gssproxy -D
root        3818  0.0  0.1 1240692 19328 ?       Ssl  00:06   0:00 /usr/bin/amazon-ssm-agent
root        3827  0.0  0.0  14376  7888 ?        Ss   00:06   0:00 sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups
root        3844  0.0  0.0   4764  2616 ?        Ss   00:06   0:00 /usr/sbin/atd -f
root        3847  0.0  0.0 224428  3644 ?        Ss   00:06   0:00 /usr/sbin/crond -n
root        8745  0.0  0.0 224428  2464 ?        S    00:15   0:00  \_ /usr/sbin/CROND -n
root        8746  0.0  0.0 222964  3300 ?        Ss   00:15   0:00      \_ /bin/sh -c timeout -s SIGKILL 2h /usr/bin/dump-instance-state full 10 > /emr/instance-state/instance-state.log-`date +%Y-%m-%d-%H-%M` 2>&1
root        8747  0.0  0.0 221380  1004 ?        S    00:15   0:00          \_ timeout -s SIGKILL 2h /usr/bin/dump-instance-state full 10
root        8749  0.0  0.0 222964  3448 ?        S    00:15   0:00              \_ /usr/bin/bash /usr/bin/dump-instance-state full 10
root        9826  0.0  0.0 223752  2944 ?        R    00:17   0:00                  \_ ps auxwwwf
root        3848  0.0  0.0 221360  1076 tty1     Ss+  00:06   0:00 /sbin/agetty -o -p -- \u --noclear - linux
root        3849  0.0  0.0 221404  1064 ttyS0    Ss+  00:06   0:00 /sbin/agetty -o -p -- \u --keep-baud 115200,57600,38400,9600 - vt220
chrony      3859  0.0  0.0  86452  3916 ?        S    00:06   0:00 /usr/sbin/chronyd -F 2
root        4123  2.6  2.6 4975000 418364 ?      Sl   00:06   0:18 /usr/lib/jvm/jre-17/bin/java -Xmx1024m -XX:+ExitOnOutOfMemoryError -XX:MinHeapFreeRatio=10 -server -cp /usr/share/aws/emr/instance-controller/lib/*:/home/hadoop/conf:/usr/share/aws/aws-java-sdk-v2/* -Dlog4j2.configurationFile=file:/etc/logpusher/log4j2.xml -Dlog4j2.formatMsgNoLookups=true -Dlog4j2.disable.jmx=true aws157.logpusher.Main /etc/logpusher/logpusher.properties
root        4150  0.7  1.1 5116444 187528 ?      Sl   00:06   0:04 /usr/lib/jvm/java-17-amazon-corretto.x86_64/bin/java -Xmx1500m -Xms300m -XX:+ExitOnOutOfMemoryError -XX:MinHeapFreeRatio=10 -cp /usr/share/aws/aws-java-sdk-v2/*:/usr/share/aws/emr/emr-log-analytics-metrics/lib/*:/home/hadoop/conf -Dlog4j.defaultInitOverride aws157.apppusher.Main
root        4190  0.0  0.0  16352  6404 ?        Ss   00:06   0:00 /usr/lib/systemd/systemd-userdbd
root        9329  0.0  0.0  16944  7596 ?        S    00:16   0:00  \_ systemd-userwork: waiting...
root        9330  0.0  0.0  16944  7604 ?        S    00:16   0:00  \_ systemd-userwork: waiting...
root        9331  0.0  0.0  16944  7668 ?        S    00:16   0:00  \_ systemd-userwork: waiting...
hadoop      4249  3.5  2.7 4972600 447460 ?      Sl   00:06   0:23 /usr/lib/jvm/jre-17/bin/java -Djava.security.properties=/emr/instance-controller/lib/security.properties -Xmx1024m -Djute.maxbuffer=3145728 -XX:+ExitOnOutOfMemoryError -XX:MinHeapFreeRatio=10 -server -cp /usr/share/aws/emr/instance-controller/lib/*:/home/hadoop/conf:/usr/share/aws/aws-java-sdk-v2/* -Dlog4j2.configurationFile=file:/etc/instance-controller/log4j2.xml -Dlog4j2.formatMsgNoLookups=true -Dlog4j2.disable.jmx=true aws157.instancecontroller.Main
root        4460  0.0  0.0 234504  8280 ?        S    00:06   0:00 sudo -u hadoop yarn app --list --appStates ALL
hadoop      4544  0.4  0.9 5944208 154376 ?      Sl   00:06   0:03  \_ /etc/alternatives/jre/bin/java -Dproc_app -Djava.net.preferIPv4Stack=true -Dsun.net.inetaddr.ttl=30 -Dservice.libdir=/usr/lib/hadoop-yarn/./,/usr/lib/hadoop-yarn/lib,/usr/lib/hadoop-hdfs/./,/usr/lib/hadoop-hdfs/lib,/usr/lib/hadoop/./,/usr/lib/hadoop/lib -Dyarn.log.dir=/usr/lib/hadoop/logs -Dyarn.log.file=hadoop.log -Dyarn.home.dir=/usr/lib/hadoop-yarn -Dyarn.root.logger=INFO,console -Djava.library.path=/usr/lib/hadoop/lib/native -Dhadoop.log.dir=/usr/lib/hadoop/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/lib/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.yarn.client.cli.ApplicationCLI app --list --appStates ALL
root        4462  0.0  0.0 221812  2284 ?        S    00:06   0:00 grep application_
root        4463  0.0  0.0 224652  3208 ?        S    00:06   0:00 awk -F\t {gsub(/^ +| +$/, "", $1);gsub(/^ +| +$/, "", $6);gsub(/^ +| +$/, "", $10); print $1 "," $6 "," $10}
hadoop      4533  0.0  0.0  22216 14336 ?        Ss   00:06   0:00 /usr/lib/systemd/systemd --user
hadoop      4536  0.0  0.0 174308  7192 ?        S    00:06   0:00  \_ (sd-pam)
root        5095  0.0  0.2 1957716 43676 ?       Ssl  00:07   0:00 /usr/bin/containerd
root        5142  0.0  0.5 2003768 83724 ?       Ssl  00:07   0:00 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --default-ulimit nofile=32768:65536
hdfs        5920  1.5  2.0 2887740 326180 ?      Sl   00:07   0:09 /usr/lib/jvm/jre-17/bin/java -Dproc_datanode -Djava.net.preferIPv4Stack=true -server -XX:+ExitOnOutOfMemoryError --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.base/sun.security.x509=ALL-UNNAMED --add-exports=java.base/sun.security.util=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util.regex=ALL-UNNAMED --add-opens=java.base/jdk.internal=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/jdk.internal.reflect=ALL-UNNAMED --add-opens=java.sql/java.sql=ALL-UNNAMED --add-opens=java.base/jdk.internal.util=ALL-UNNAMED --add-opens=java.base/jdk.internal.util.random=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED -Dhadoop.security.logger=ERROR,DRFAS -Dyarn.log.dir=/var/log/hadoop-hdfs -Dyarn.log.file=hadoop-hdfs-datanode-ip-172-31-41-235.ec2.internal.log -Dyarn.home.dir=/usr/lib/hadoop-yarn -Dyarn.root.logger=INFO,console -Djava.library.path=:/usr/lib/hadoop-lzo/lib/native:/usr/lib/hadoop/lib/native -Xmx778m -Dhadoop.log.dir=/var/log/hadoop-hdfs -Dhadoop.log.file=hadoop-hdfs-datanode-ip-172-31-41-235.ec2.internal.log -Dhadoop.home.dir=/usr/lib/hadoop -Dhadoop.id.str=hdfs -Dhadoop.root.logger=INFO,DRFA -Dhadoop.policy.file=hadoop-policy.xml -Dsun.net.inetaddr.ttl=3600 org.apache.hadoop.hdfs.server.datanode.DataNode
yarn        6527  5.3  3.1 4393668 504540 ?      Sl   00:09   0:26 /usr/lib/jvm/jre-17/bin/java -Dproc_nodemanager -Djava.net.preferIPv4Stack=true -server -XX:+ExitOnOutOfMemoryError --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.base/sun.security.x509=ALL-UNNAMED --add-exports=java.base/sun.security.util=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util.regex=ALL-UNNAMED --add-opens=java.base/jdk.internal=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/jdk.internal.reflect=ALL-UNNAMED --add-opens=java.sql/java.sql=ALL-UNNAMED --add-opens=java.base/jdk.internal.util=ALL-UNNAMED --add-opens=java.base/jdk.internal.util.random=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED -XX:+ExitOnOutOfMemoryError -Dsun.net.inetaddr.ttl=30 -Dyarn.log.dir=/var/log/hadoop-yarn -Dyarn.log.file=hadoop-yarn-nodemanager-ip-172-31-41-235.ec2.internal.log -Dyarn.home.dir=/usr/lib/hadoop-yarn -Dyarn.root.logger=INFO,console -Djava.library.path=:/usr/lib/hadoop-lzo/lib/native:/usr/lib/hadoop/lib/native -Xmx2048m -Dhadoop.log.dir=/var/log/hadoop-yarn -Dhadoop.log.file=hadoop-yarn-nodemanager-ip-172-31-41-235.ec2.internal.log -Dhadoop.home.dir=/usr/lib/hadoop -Dhadoop.id.str=yarn -Dhadoop.root.logger=INFO,DRFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.yarn.server.nodemanager.NodeManager
yarn        9749  0.0  0.0   4248  3116 ?        S    00:17   0:00  \_ bash /mnt1/yarn/usercache/hadoop/appcache/application_1769040496349_0002/container_1769040496349_0002_01_000001/default_container_executor.sh
yarn        9751  0.0  0.0   4248  3184 ?        Ss   00:17   0:00      \_ /bin/bash -c /usr/lib/jvm/jre-17/bin/java -Djava.io.tmpdir=/mnt1/yarn/usercache/hadoop/appcache/application_1769040496349_0002/container_1769040496349_0002_01_000001/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1769040496349_0002/container_1769040496349_0002_01_000001 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx4915m --add-opens=java.base/java.lang=ALL-UNNAMED --add-exports=java.base/sun.net.dns=ALL-UNNAMED --add-exports=java.base/sun.net.util=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.regex=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/javax.script=ALL-UNNAMED -Dillegal-access=permit --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/jdk.internal.reflect=ALL-UNNAMED --add-opens=java.base/jdk.internal.util.random=ALL-UNNAMED --add-opens=java.base/jdk.internal.util=ALL-UNNAMED --add-opens=java.base/jdk.internal=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=java.sql/java.sql=ALL-UNNAMED --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1>/var/log/hadoop-yarn/containers/application_1769040496349_0002/container_1769040496349_0002_01_000001/stdout 2>/var/log/hadoop-yarn/containers/application_1769040496349_0002/container_1769040496349_0002_01_000001/stderr 
yarn        9764  242  2.6 7034384 426420 ?      Sl   00:17   0:09          \_ /usr/lib/jvm/jre-17/bin/java -Djava.io.tmpdir=/mnt1/yarn/usercache/hadoop/appcache/application_1769040496349_0002/container_1769040496349_0002_01_000001/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1769040496349_0002/container_1769040496349_0002_01_000001 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Xmx4915m --add-opens=java.base/java.lang=ALL-UNNAMED --add-exports=java.base/sun.net.dns=ALL-UNNAMED --add-exports=java.base/sun.net.util=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.regex=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/javax.script=ALL-UNNAMED -Dillegal-access=permit --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/jdk.internal.reflect=ALL-UNNAMED --add-opens=java.base/jdk.internal.util.random=ALL-UNNAMED --add-opens=java.base/jdk.internal.util=ALL-UNNAMED --add-opens=java.base/jdk.internal=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=java.sql/java.sql=ALL-UNNAMED --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED org.apache.hadoop.mapreduce.v2.app.MRAppMaster
root        9662  1.4  0.0  22180 14360 ?        Ss   00:17   0:00 /usr/lib/systemd/systemd --user
root        9664  0.0  0.0 174308  7336 ?        S    00:17   0:00  \_ (sd-pam)

# Top CPU users
ps auxwww --sort -%cpu | head -20
USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
yarn        9764  244  2.6 7034384 426740 ?      Sl   00:17   0:09 /usr/lib/jvm/jre-17/bin/java -Djava.io.tmpdir=/mnt1/yarn/usercache/hadoop/appcache/application_1769040496349_0002/container_1769040496349_0002_01_000001/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1769040496349_0002/container_1769040496349_0002_01_000001 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Xmx4915m --add-opens=java.base/java.lang=ALL-UNNAMED --add-exports=java.base/sun.net.dns=ALL-UNNAMED --add-exports=java.base/sun.net.util=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.regex=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/javax.script=ALL-UNNAMED -Dillegal-access=permit --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/jdk.internal.reflect=ALL-UNNAMED --add-opens=java.base/jdk.internal.util.random=ALL-UNNAMED --add-opens=java.base/jdk.internal.util=ALL-UNNAMED --add-opens=java.base/jdk.internal=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=java.sql/java.sql=ALL-UNNAMED --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED org.apache.hadoop.mapreduce.v2.app.MRAppMaster
yarn        6527  5.3  3.1 4393668 504540 ?      Sl   00:09   0:26 /usr/lib/jvm/jre-17/bin/java -Dproc_nodemanager -Djava.net.preferIPv4Stack=true -server -XX:+ExitOnOutOfMemoryError --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.base/sun.security.x509=ALL-UNNAMED --add-exports=java.base/sun.security.util=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util.regex=ALL-UNNAMED --add-opens=java.base/jdk.internal=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/jdk.internal.reflect=ALL-UNNAMED --add-opens=java.sql/java.sql=ALL-UNNAMED --add-opens=java.base/jdk.internal.util=ALL-UNNAMED --add-opens=java.base/jdk.internal.util.random=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED -XX:+ExitOnOutOfMemoryError -Dsun.net.inetaddr.ttl=30 -Dyarn.log.dir=/var/log/hadoop-yarn -Dyarn.log.file=hadoop-yarn-nodemanager-ip-172-31-41-235.ec2.internal.log -Dyarn.home.dir=/usr/lib/hadoop-yarn -Dyarn.root.logger=INFO,console -Djava.library.path=:/usr/lib/hadoop-lzo/lib/native:/usr/lib/hadoop/lib/native -Xmx2048m -Dhadoop.log.dir=/var/log/hadoop-yarn -Dhadoop.log.file=hadoop-yarn-nodemanager-ip-172-31-41-235.ec2.internal.log -Dhadoop.home.dir=/usr/lib/hadoop -Dhadoop.id.str=yarn -Dhadoop.root.logger=INFO,DRFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.yarn.server.nodemanager.NodeManager
hadoop      4249  3.5  2.7 4972600 447460 ?      Sl   00:06   0:23 /usr/lib/jvm/jre-17/bin/java -Djava.security.properties=/emr/instance-controller/lib/security.properties -Xmx1024m -Djute.maxbuffer=3145728 -XX:+ExitOnOutOfMemoryError -XX:MinHeapFreeRatio=10 -server -cp /usr/share/aws/emr/instance-controller/lib/*:/home/hadoop/conf:/usr/share/aws/aws-java-sdk-v2/* -Dlog4j2.configurationFile=file:/etc/instance-controller/log4j2.xml -Dlog4j2.formatMsgNoLookups=true -Dlog4j2.disable.jmx=true aws157.instancecontroller.Main
root        4123  2.6  2.6 4975000 418364 ?      Sl   00:06   0:18 /usr/lib/jvm/jre-17/bin/java -Xmx1024m -XX:+ExitOnOutOfMemoryError -XX:MinHeapFreeRatio=10 -server -cp /usr/share/aws/emr/instance-controller/lib/*:/home/hadoop/conf:/usr/share/aws/aws-java-sdk-v2/* -Dlog4j2.configurationFile=file:/etc/logpusher/log4j2.xml -Dlog4j2.formatMsgNoLookups=true -Dlog4j2.disable.jmx=true aws157.logpusher.Main /etc/logpusher/logpusher.properties
hdfs        5920  1.5  2.0 2887740 326180 ?      Sl   00:07   0:09 /usr/lib/jvm/jre-17/bin/java -Dproc_datanode -Djava.net.preferIPv4Stack=true -server -XX:+ExitOnOutOfMemoryError --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.base/sun.security.x509=ALL-UNNAMED --add-exports=java.base/sun.security.util=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util.regex=ALL-UNNAMED --add-opens=java.base/jdk.internal=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/jdk.internal.reflect=ALL-UNNAMED --add-opens=java.sql/java.sql=ALL-UNNAMED --add-opens=java.base/jdk.internal.util=ALL-UNNAMED --add-opens=java.base/jdk.internal.util.random=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED -Dhadoop.security.logger=ERROR,DRFAS -Dyarn.log.dir=/var/log/hadoop-hdfs -Dyarn.log.file=hadoop-hdfs-datanode-ip-172-31-41-235.ec2.internal.log -Dyarn.home.dir=/usr/lib/hadoop-yarn -Dyarn.root.logger=INFO,console -Djava.library.path=:/usr/lib/hadoop-lzo/lib/native:/usr/lib/hadoop/lib/native -Xmx778m -Dhadoop.log.dir=/var/log/hadoop-hdfs -Dhadoop.log.file=hadoop-hdfs-datanode-ip-172-31-41-235.ec2.internal.log -Dhadoop.home.dir=/usr/lib/hadoop -Dhadoop.id.str=hdfs -Dhadoop.root.logger=INFO,DRFA -Dhadoop.policy.file=hadoop-policy.xml -Dsun.net.inetaddr.ttl=3600 org.apache.hadoop.hdfs.server.datanode.DataNode
root        9662  1.4  0.0  22180 14360 ?        Ss   00:17   0:00 /usr/lib/systemd/systemd --user
root           1  0.7  0.1 172968 17964 ?        Ss   00:05   0:05 /usr/lib/systemd/systemd --switched-root --system --deserialize=32
root        4150  0.7  1.1 5116444 187528 ?      Sl   00:06   0:04 /usr/lib/jvm/java-17-amazon-corretto.x86_64/bin/java -Xmx1500m -Xms300m -XX:+ExitOnOutOfMemoryError -XX:MinHeapFreeRatio=10 -cp /usr/share/aws/aws-java-sdk-v2/*:/usr/share/aws/emr/emr-log-analytics-metrics/lib/*:/home/hadoop/conf -Dlog4j.defaultInitOverride aws157.apppusher.Main
hadoop      4544  0.4  0.9 5944208 154376 ?      Sl   00:06   0:03 /etc/alternatives/jre/bin/java -Dproc_app -Djava.net.preferIPv4Stack=true -Dsun.net.inetaddr.ttl=30 -Dservice.libdir=/usr/lib/hadoop-yarn/./,/usr/lib/hadoop-yarn/lib,/usr/lib/hadoop-hdfs/./,/usr/lib/hadoop-hdfs/lib,/usr/lib/hadoop/./,/usr/lib/hadoop/lib -Dyarn.log.dir=/usr/lib/hadoop/logs -Dyarn.log.file=hadoop.log -Dyarn.home.dir=/usr/lib/hadoop-yarn -Dyarn.root.logger=INFO,console -Djava.library.path=/usr/lib/hadoop/lib/native -Dhadoop.log.dir=/usr/lib/hadoop/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/lib/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.yarn.client.cli.ApplicationCLI app --list --appStates ALL
root        1039  0.1  0.1  54092 18828 ?        Ss   00:05   0:00 /usr/lib/systemd/systemd-journald
root           2  0.0  0.0      0     0 ?        S    00:05   0:00 [kthreadd]
root           3  0.0  0.0      0     0 ?        I<   00:05   0:00 [rcu_gp]
root           4  0.0  0.0      0     0 ?        I<   00:05   0:00 [rcu_par_gp]
root           5  0.0  0.0      0     0 ?        I<   00:05   0:00 [slub_flushwq]
root           6  0.0  0.0      0     0 ?        I<   00:05   0:00 [netns]
root           7  0.0  0.0      0     0 ?        I    00:05   0:00 [kworker/0:0-events]
root           8  0.0  0.0      0     0 ?        I<   00:05   0:00 [kworker/0:0H-events_highpri]
root          10  0.0  0.0      0     0 ?        I<   00:05   0:00 [mm_percpu_wq]
root          11  0.0  0.0      0     0 ?        I    00:05   0:00 [rcu_tasks_kthread]

# Top memory users
ps auxwww --sort -rss | head -20
USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
yarn        6527  5.3  3.1 4393668 504808 ?      Sl   00:09   0:26 /usr/lib/jvm/jre-17/bin/java -Dproc_nodemanager -Djava.net.preferIPv4Stack=true -server -XX:+ExitOnOutOfMemoryError --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.base/sun.security.x509=ALL-UNNAMED --add-exports=java.base/sun.security.util=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util.regex=ALL-UNNAMED --add-opens=java.base/jdk.internal=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/jdk.internal.reflect=ALL-UNNAMED --add-opens=java.sql/java.sql=ALL-UNNAMED --add-opens=java.base/jdk.internal.util=ALL-UNNAMED --add-opens=java.base/jdk.internal.util.random=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED -XX:+ExitOnOutOfMemoryError -Dsun.net.inetaddr.ttl=30 -Dyarn.log.dir=/var/log/hadoop-yarn -Dyarn.log.file=hadoop-yarn-nodemanager-ip-172-31-41-235.ec2.internal.log -Dyarn.home.dir=/usr/lib/hadoop-yarn -Dyarn.root.logger=INFO,console -Djava.library.path=:/usr/lib/hadoop-lzo/lib/native:/usr/lib/hadoop/lib/native -Xmx2048m -Dhadoop.log.dir=/var/log/hadoop-yarn -Dhadoop.log.file=hadoop-yarn-nodemanager-ip-172-31-41-235.ec2.internal.log -Dhadoop.home.dir=/usr/lib/hadoop -Dhadoop.id.str=yarn -Dhadoop.root.logger=INFO,DRFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.yarn.server.nodemanager.NodeManager
hadoop      4249  3.5  2.7 4972600 447460 ?      Sl   00:06   0:23 /usr/lib/jvm/jre-17/bin/java -Djava.security.properties=/emr/instance-controller/lib/security.properties -Xmx1024m -Djute.maxbuffer=3145728 -XX:+ExitOnOutOfMemoryError -XX:MinHeapFreeRatio=10 -server -cp /usr/share/aws/emr/instance-controller/lib/*:/home/hadoop/conf:/usr/share/aws/aws-java-sdk-v2/* -Dlog4j2.configurationFile=file:/etc/instance-controller/log4j2.xml -Dlog4j2.formatMsgNoLookups=true -Dlog4j2.disable.jmx=true aws157.instancecontroller.Main
yarn        9764  245  2.6 7034384 426812 ?      Sl   00:17   0:09 /usr/lib/jvm/jre-17/bin/java -Djava.io.tmpdir=/mnt1/yarn/usercache/hadoop/appcache/application_1769040496349_0002/container_1769040496349_0002_01_000001/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/containers/application_1769040496349_0002/container_1769040496349_0002_01_000001 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog -Xmx4915m --add-opens=java.base/java.lang=ALL-UNNAMED --add-exports=java.base/sun.net.dns=ALL-UNNAMED --add-exports=java.base/sun.net.util=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.regex=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/javax.script=ALL-UNNAMED -Dillegal-access=permit --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/jdk.internal.reflect=ALL-UNNAMED --add-opens=java.base/jdk.internal.util.random=ALL-UNNAMED --add-opens=java.base/jdk.internal.util=ALL-UNNAMED --add-opens=java.base/jdk.internal=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=java.sql/java.sql=ALL-UNNAMED --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED org.apache.hadoop.mapreduce.v2.app.MRAppMaster
root        4123  2.6  2.6 4975000 418364 ?      Sl   00:06   0:18 /usr/lib/jvm/jre-17/bin/java -Xmx1024m -XX:+ExitOnOutOfMemoryError -XX:MinHeapFreeRatio=10 -server -cp /usr/share/aws/emr/instance-controller/lib/*:/home/hadoop/conf:/usr/share/aws/aws-java-sdk-v2/* -Dlog4j2.configurationFile=file:/etc/logpusher/log4j2.xml -Dlog4j2.formatMsgNoLookups=true -Dlog4j2.disable.jmx=true aws157.logpusher.Main /etc/logpusher/logpusher.properties
hdfs        5920  1.5  2.0 2887740 326180 ?      Sl   00:07   0:09 /usr/lib/jvm/jre-17/bin/java -Dproc_datanode -Djava.net.preferIPv4Stack=true -server -XX:+ExitOnOutOfMemoryError --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.base/sun.security.x509=ALL-UNNAMED --add-exports=java.base/sun.security.util=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util.regex=ALL-UNNAMED --add-opens=java.base/jdk.internal=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/jdk.internal.reflect=ALL-UNNAMED --add-opens=java.sql/java.sql=ALL-UNNAMED --add-opens=java.base/jdk.internal.util=ALL-UNNAMED --add-opens=java.base/jdk.internal.util.random=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED -Dhadoop.security.logger=ERROR,DRFAS -Dyarn.log.dir=/var/log/hadoop-hdfs -Dyarn.log.file=hadoop-hdfs-datanode-ip-172-31-41-235.ec2.internal.log -Dyarn.home.dir=/usr/lib/hadoop-yarn -Dyarn.root.logger=INFO,console -Djava.library.path=:/usr/lib/hadoop-lzo/lib/native:/usr/lib/hadoop/lib/native -Xmx778m -Dhadoop.log.dir=/var/log/hadoop-hdfs -Dhadoop.log.file=hadoop-hdfs-datanode-ip-172-31-41-235.ec2.internal.log -Dhadoop.home.dir=/usr/lib/hadoop -Dhadoop.id.str=hdfs -Dhadoop.root.logger=INFO,DRFA -Dhadoop.policy.file=hadoop-policy.xml -Dsun.net.inetaddr.ttl=3600 org.apache.hadoop.hdfs.server.datanode.DataNode
root        4150  0.7  1.1 5116444 187528 ?      Sl   00:06   0:04 /usr/lib/jvm/java-17-amazon-corretto.x86_64/bin/java -Xmx1500m -Xms300m -XX:+ExitOnOutOfMemoryError -XX:MinHeapFreeRatio=10 -cp /usr/share/aws/aws-java-sdk-v2/*:/usr/share/aws/emr/emr-log-analytics-metrics/lib/*:/home/hadoop/conf -Dlog4j.defaultInitOverride aws157.apppusher.Main
hadoop      4544  0.4  0.9 5944208 154376 ?      Sl   00:06   0:03 /etc/alternatives/jre/bin/java -Dproc_app -Djava.net.preferIPv4Stack=true -Dsun.net.inetaddr.ttl=30 -Dservice.libdir=/usr/lib/hadoop-yarn/./,/usr/lib/hadoop-yarn/lib,/usr/lib/hadoop-hdfs/./,/usr/lib/hadoop-hdfs/lib,/usr/lib/hadoop/./,/usr/lib/hadoop/lib -Dyarn.log.dir=/usr/lib/hadoop/logs -Dyarn.log.file=hadoop.log -Dyarn.home.dir=/usr/lib/hadoop-yarn -Dyarn.root.logger=INFO,console -Djava.library.path=/usr/lib/hadoop/lib/native -Dhadoop.log.dir=/usr/lib/hadoop/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/lib/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.yarn.client.cli.ApplicationCLI app --list --appStates ALL
root        5142  0.0  0.5 2003768 83724 ?       Ssl  00:07   0:00 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --default-ulimit nofile=32768:65536
root        5095  0.0  0.2 1957716 43676 ?       Ssl  00:07   0:00 /usr/bin/containerd
root        3818  0.0  0.1 1240692 19328 ?       Ssl  00:06   0:00 /usr/bin/amazon-ssm-agent
root        1039  0.1  0.1  54092 18828 ?        Ss   00:05   0:00 /usr/lib/systemd/systemd-journald
root           1  0.7  0.1 172968 17964 ?        Ss   00:05   0:05 /usr/lib/systemd/systemd --switched-root --system --deserialize=32
systemd+    1610  0.0  0.0  22600 15004 ?        Ss   00:05   0:00 /usr/lib/systemd/systemd-resolved
root        9662  1.4  0.0  22180 14360 ?        Ss   00:17   0:00 /usr/lib/systemd/systemd --user
hadoop      4533  0.0  0.0  22216 14336 ?        Ss   00:06   0:00 /usr/lib/systemd/systemd --user
root        1611  0.0  0.0  32028 11604 ?        Ss   00:05   0:00 /usr/lib/systemd/systemd-udevd
root        1804  0.0  0.0  19136 11088 ?        Ss   00:05   0:00 /usr/lib/systemd/systemd-logind
systemd+    1846  0.0  0.0 236948  9940 ?        Ss   00:05   0:00 /usr/lib/systemd/systemd-networkd
root        4460  0.0  0.0 234504  8280 ?        S    00:06   0:00 sudo -u hadoop yarn app --list --appStates ALL

# hows the kernel looking
dmesg | tail -n 25
[   19.210945] XFS (nvme1n1p1): Mounting V5 Filesystem
[   19.250527] XFS (nvme1n1p1): Ending clean mount
[   19.290206] XFS (nvme1n1p2): Mounting V5 Filesystem
[   19.337074] XFS (nvme1n1p2): Ending clean mount
[   19.339853] XFS (nvme1n1p2): Quotacheck needed: Please wait.
[   19.344438] XFS (nvme1n1p2): Quotacheck: Done.
[   19.376499] XFS (nvme2n1): Mounting V5 Filesystem
[   19.418569] XFS (nvme2n1): Ending clean mount
[   19.421585] XFS (nvme2n1): Quotacheck needed: Please wait.
[   19.426142] XFS (nvme2n1): Quotacheck: Done.
[   24.475481] systemd-journald[1039]: /var/log/journal/ec276fc410ae8f3bf6c5605dc1bcdbc7/system.journal: Journal file has been deleted, rotating.
[   24.477245] systemd-journald[1039]: Failed to write entry to /var/log/journal/ec276fc410ae8f3bf6c5605dc1bcdbc7/system.journal (22 items, 662 bytes), rotating before retrying: Identifier removed
[   26.613757] zram_generator::config[3965]: zram0: system has too much memory (15611MB), limit is 800MB, ignoring.
[   26.997667] zram_generator::config[4082]: zram0: system has too much memory (15611MB), limit is 800MB, ignoring.
[  100.250276] zram_generator::config[5087]: zram0: system has too much memory (15611MB), limit is 800MB, ignoring.
[  109.873130] bridge: filtering via arp/ip/ip6tables is no longer available by default. Update your scripts to load br_netfilter if you need this.
[  109.910470] Bridge firewalling registered
[  110.514577] Initializing XFRM netlink socket
[  111.043807] zram_generator::config[5379]: zram0: system has too much memory (15611MB), limit is 800MB, ignoring.
[  111.337263] zram_generator::config[5404]: zram0: system has too much memory (15611MB), limit is 800MB, ignoring.
[  116.835634] zram_generator::config[5882]: zram0: system has too much memory (15611MB), limit is 800MB, ignoring.
[  119.322389] zram_generator::config[5981]: zram0: system has too much memory (15611MB), limit is 800MB, ignoring.
[  119.775525] zram_generator::config[6010]: zram0: system has too much memory (15611MB), limit is 800MB, ignoring.
[  121.657080] zram_generator::config[6239]: zram0: system has too much memory (15611MB), limit is 800MB, ignoring.
[  121.912380] zram_generator::config[6264]: zram0: system has too much memory (15611MB), limit is 800MB, ignoring.

# dump instance controller log
tail -n 100 /emr/instance-controller/log/instance-controller.log
2026-01-22 00:16:18,791 INFO instance-metrics-collector-4: Starting Command: [sh /usr/bin//memmet.sh null]
2026-01-22 00:16:18,800 INFO instance-metrics-collector-4: Completed Command: [sh /usr/bin//memmet.sh null] in 9ms, exitCode: 0, hadExceptionsInExecution?: false, 
2026-01-22 00:16:20,791 INFO instance-metrics-collector-1: Starting Command: [sh /usr/bin//cpumet.sh null]
2026-01-22 00:16:21,798 INFO instance-metrics-collector-1: Completed Command: [sh /usr/bin//cpumet.sh null] in 1006ms, exitCode: 0, hadExceptionsInExecution?: false, 
2026-01-22 00:16:21,884 INFO arpc-307: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:16:21,892 INFO arpc-475: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:16:21,894 INFO arpc-104: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:16:22,746 INFO RemoteInstanceStateUpdater: Got 2 signed policies from master
2026-01-22 00:16:22,747 INFO RemoteInstanceStateUpdater: save policy to db: SignedPolicy SYSTEM_LOG bucket: aws157-logs-prod prefix: j-1012I6B4RWP1O/ expiration: 2026-01-22 01:06:49.934 AM
2026-01-22 00:16:22,748 INFO RemoteInstanceStateUpdater: save policy to db: SignedPolicy USER_LOG bucket: cfggii23 prefix: dsp2/logs/j-1012I6B4RWP1O/ expiration: 2026-01-22 01:06:49.963 AM
2026-01-22 00:16:22,752 INFO RemoteInstanceStateUpdater: Parsing ComponentConfigurations.
2026-01-22 00:16:22,752 INFO RemoteInstanceStateUpdater: Initializing Hadoop configurations
2026-01-22 00:16:22,753 INFO RemoteInstanceStateUpdater: ResourceManagerHostnames already populated, updating yarn-site
2026-01-22 00:16:22,753 INFO RemoteInstanceStateUpdater: hadoopConfDir /etc/hadoop/conf/
2026-01-22 00:16:22,753 INFO RemoteInstanceStateUpdater: Apps installed []
2026-01-22 00:16:22,753 INFO RemoteInstanceStateUpdater: Kerberos classification not found, it is not a Kerberos cluster.
2026-01-22 00:16:22,753 INFO RemoteInstanceStateUpdater: It is not an external KDC cluster, not setting KerberosReadyToShutDown in common instance record.
2026-01-22 00:16:22,753 INFO RemoteInstanceStateUpdater: Not Starting Kerberos Refresher, since its not a kerberized cluster
2026-01-22 00:16:22,753 INFO RemoteInstanceStateUpdater: ClusterConfigurationUpdateHandler Received Managed resize Configuration as null
2026-01-22 00:16:22,753 INFO RemoteInstanceStateUpdater: Touching heartbeat file: uplink
2026-01-22 00:16:22,753 INFO RemoteInstanceStateUpdater: Sleeping for '60000'
2026-01-22 00:16:22,792 INFO instance-metrics-collector-2: Starting Command: [sh /usr/bin//diskmet.sh null]
2026-01-22 00:16:22,881 INFO MetricsCollectorCoreTaskManager-1: Calling GetManagedResizeConfigurationForWorkerRequest RPC.
2026-01-22 00:16:22,909 INFO MetricsCollectorCoreTaskManager-1: Received GetManagedResizeConfigurationForWorkerRequest response, isManagedResizeEnabled is false.
2026-01-22 00:16:22,909 INFO MetricsCollectorCoreTaskManager-1: Instance level metrics frequencies are not set, so we will not start MetricCollector on Core/Task Instances.
2026-01-22 00:16:23,062 INFO arpc-473: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:16:23,569 INFO instance-metrics-collector-2: Completed Command: [sh /usr/bin//diskmet.sh null] in 777ms, exitCode: 0, hadExceptionsInExecution?: false, 
2026-01-22 00:16:24,794 INFO instance-metrics-collector-3: Starting Command: [sh /usr/bin//proc_cpu_mem.sh null]
2026-01-22 00:16:26,888 INFO arpc-433: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:16:26,989 INFO instance-metrics-collector-3: Completed Command: [sh /usr/bin//proc_cpu_mem.sh null] in 2195ms, exitCode: 0, hadExceptionsInExecution?: false, 
2026-01-22 00:16:28,078 INFO arpc-307: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:16:31,886 INFO arpc-473: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:16:33,091 INFO arpc-475: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:16:35,500 INFO healthSignalMonitor: Sleeping for '30000'
2026-01-22 00:16:36,892 INFO arpc-307: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:16:38,104 INFO arpc-473: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:16:41,887 INFO arpc-433: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:16:43,132 INFO arpc-307: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:16:46,887 INFO arpc-475: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:16:48,145 INFO arpc-433: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:16:51,040 INFO JobFlowStateUpdater: Masking ComponentConfiguration for classification: hdfs-site
2026-01-22 00:16:51,040 INFO JobFlowStateUpdater: Masking ComponentConfiguration for classification: httpfs-site
2026-01-22 00:16:51,040 INFO JobFlowStateUpdater: Masking ComponentConfiguration for classification: hadoop-env
2026-01-22 00:16:51,040 INFO JobFlowStateUpdater: Masking ComponentConfiguration for classification: yarn-env
2026-01-22 00:16:51,040 INFO JobFlowStateUpdater: Masking ComponentConfiguration for classification: yarn-site
2026-01-22 00:16:51,040 INFO JobFlowStateUpdater: Masking ComponentConfiguration for classification: mapred-site
2026-01-22 00:16:51,040 INFO JobFlowStateUpdater: Masking ComponentConfiguration for classification: core-site
2026-01-22 00:16:51,040 INFO JobFlowStateUpdater: Masking ComponentConfiguration for classification: hdfs-site
2026-01-22 00:16:51,040 INFO JobFlowStateUpdater: Masking ComponentConfiguration for classification: httpfs-site
2026-01-22 00:16:51,040 INFO JobFlowStateUpdater: Masking ComponentConfiguration for classification: hadoop-env
2026-01-22 00:16:51,040 INFO JobFlowStateUpdater: Masking ComponentConfiguration for classification: yarn-env
2026-01-22 00:16:51,040 INFO JobFlowStateUpdater: Masking ComponentConfiguration for classification: yarn-site
2026-01-22 00:16:51,040 INFO JobFlowStateUpdater: Masking ComponentConfiguration for classification: mapred-site
2026-01-22 00:16:51,040 INFO JobFlowStateUpdater: Masking ComponentConfiguration for classification: core-site
2026-01-22 00:16:51,044 INFO JobFlowStateUpdater: Sleeping for 120000
2026-01-22 00:16:51,887 INFO arpc-307: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:16:52,874 INFO MetricsCollectorCoreTaskManager-1: Calling GetManagedResizeConfigurationForWorkerRequest RPC.
2026-01-22 00:16:52,897 INFO MetricsCollectorCoreTaskManager-1: Received GetManagedResizeConfigurationForWorkerRequest response, isManagedResizeEnabled is false.
2026-01-22 00:16:52,897 INFO MetricsCollectorCoreTaskManager-1: Instance level metrics frequencies are not set, so we will not start MetricCollector on Core/Task Instances.
2026-01-22 00:16:53,160 INFO arpc-475: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:16:56,885 INFO arpc-473: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:16:58,171 INFO arpc-433: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:17:01,885 INFO arpc-475: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:17:03,182 INFO arpc-473: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:17:05,888 INFO healthSignalMonitor: Sleeping for '30000'
2026-01-22 00:17:06,886 INFO arpc-475: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:17:08,194 INFO arpc-433: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:17:11,888 INFO arpc-473: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:17:13,208 INFO arpc-475: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:17:16,887 INFO arpc-433: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:17:18,220 INFO arpc-473: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:17:18,739 INFO logpusher-manager-1: Starting LogPusherManager
2026-01-22 00:17:18,791 INFO instance-metrics-collector-5: Starting Command: [sh /usr/bin//memmet.sh null]
2026-01-22 00:17:18,808 INFO instance-metrics-collector-5: Completed Command: [sh /usr/bin//memmet.sh null] in 17ms, exitCode: 0, hadExceptionsInExecution?: false, 
2026-01-22 00:17:19,161 INFO logpusher-manager-1: LogPusher is running: true
2026-01-22 00:17:20,791 INFO instance-metrics-collector-1: Starting Command: [sh /usr/bin//cpumet.sh null]
2026-01-22 00:17:21,797 INFO instance-metrics-collector-1: Completed Command: [sh /usr/bin//cpumet.sh null] in 1006ms, exitCode: 0, hadExceptionsInExecution?: false, 
2026-01-22 00:17:21,884 INFO arpc-433: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:17:22,765 INFO RemoteInstanceStateUpdater: Got 2 signed policies from master
2026-01-22 00:17:22,766 INFO RemoteInstanceStateUpdater: save policy to db: SignedPolicy SYSTEM_LOG bucket: aws157-logs-prod prefix: j-1012I6B4RWP1O/ expiration: 2026-01-22 01:06:49.934 AM
2026-01-22 00:17:22,766 INFO RemoteInstanceStateUpdater: save policy to db: SignedPolicy USER_LOG bucket: cfggii23 prefix: dsp2/logs/j-1012I6B4RWP1O/ expiration: 2026-01-22 01:06:49.963 AM
2026-01-22 00:17:22,768 INFO RemoteInstanceStateUpdater: Parsing ComponentConfigurations.
2026-01-22 00:17:22,768 INFO RemoteInstanceStateUpdater: Initializing Hadoop configurations
2026-01-22 00:17:22,769 INFO RemoteInstanceStateUpdater: ResourceManagerHostnames already populated, updating yarn-site
2026-01-22 00:17:22,769 INFO RemoteInstanceStateUpdater: hadoopConfDir /etc/hadoop/conf/
2026-01-22 00:17:22,769 INFO RemoteInstanceStateUpdater: Apps installed []
2026-01-22 00:17:22,769 INFO RemoteInstanceStateUpdater: Kerberos classification not found, it is not a Kerberos cluster.
2026-01-22 00:17:22,769 INFO RemoteInstanceStateUpdater: It is not an external KDC cluster, not setting KerberosReadyToShutDown in common instance record.
2026-01-22 00:17:22,769 INFO RemoteInstanceStateUpdater: Not Starting Kerberos Refresher, since its not a kerberized cluster
2026-01-22 00:17:22,769 INFO RemoteInstanceStateUpdater: ClusterConfigurationUpdateHandler Received Managed resize Configuration as null
2026-01-22 00:17:22,769 INFO RemoteInstanceStateUpdater: Touching heartbeat file: uplink
2026-01-22 00:17:22,769 INFO RemoteInstanceStateUpdater: Sleeping for '60000'
2026-01-22 00:17:22,874 INFO MetricsCollectorCoreTaskManager-1: Calling GetManagedResizeConfigurationForWorkerRequest RPC.
2026-01-22 00:17:22,881 INFO MetricsCollectorCoreTaskManager-1: Received GetManagedResizeConfigurationForWorkerRequest response, isManagedResizeEnabled is false.
2026-01-22 00:17:22,881 INFO MetricsCollectorCoreTaskManager-1: Instance level metrics frequencies are not set, so we will not start MetricCollector on Core/Task Instances.
2026-01-22 00:17:23,231 INFO arpc-475: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:17:24,793 INFO instance-metrics-collector-2: Starting Command: [sh /usr/bin//proc_cpu_mem.sh null]
2026-01-22 00:17:26,888 INFO arpc-473: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false
2026-01-22 00:17:26,976 INFO instance-metrics-collector-2: Completed Command: [sh /usr/bin//proc_cpu_mem.sh null] in 2182ms, exitCode: 0, hadExceptionsInExecution?: false, 
2026-01-22 00:17:28,245 INFO arpc-475: Updating local logpusher decommissioning state as a result of /getStatus rpc call before: false, after: false

# dump instance controller stdout
tail -n 100 /emr/instance-controller/log/instance-controller.out
tail: cannot open '/emr/instance-controller/log/instance-controller.out' for reading: No such file or directory

# dump log pusher log
tail -n 100 /emr/logpusher/log/logpusher.log
        "flags": 0
      }
    ],
    "excludes": [
      {
        "pattern": "/.*uuid.*",
        "flags": 0
      }
    ],
    "recursive": true,
    "purgeKeys": false,
    "priority": 2,
    "deleteEmptyDirectories": true,
    "excludeArchiveDelete": [
      {
        "pattern": "/((?!.+/prelaunch).+\\.out)$",
        "flags": 0
      },
      {
        "pattern": "/.+\\.log",
        "flags": 0
      }
    ],
    "retentionPeriod": {
      "seconds": 14400,
      "nanos": 0
    },
    "maxPushDelay": {
      "seconds": 3600,
      "nanos": 0
    },
    "logTypes": [
      "USER_LOG",
      "SYSTEM_LOG"
    ],
    "deleteOnLowDisk": true,
    "checkForUserOverrides": true,
    "userOverrideResourceIdPattern": {
      "pattern": "(application_\\d+_\\d+)",
      "flags": 0
    }
  },
  {
    "localDirectory": "/var/log/hadoop-mapreduce/history",
    "s3Path": "hadoop-mapreduce/history/$0",
    "includes": [
      {
        "pattern": "/(.*)",
        "flags": 0
      }
    ],
    "excludes": [
      {
        "pattern": "/.*\\.crc$",
        "flags": 0
      }
    ],
    "recursive": true,
    "purgeKeys": true,
    "priority": 2,
    "deleteEmptyDirectories": false,
    "retentionPeriod": {
      "seconds": 172800,
      "nanos": 0
    },
    "maxPushDelay": {
      "seconds": 3600,
      "nanos": 0
    },
    "logTypes": [
      "USER_LOG",
      "SYSTEM_LOG"
    ],
    "deleteOnLowDisk": true,
    "checkForUserOverrides": false
  }
]
2026-01-22 00:15:51,103 INFO dsm-1: Single directory with 2 configurations, regexes should track disjoint sets of files:
localDirectory:'/mnt/var/log/', includes:[/(cloud-init.*)], excludes:[null]
localDirectory:'/mnt/var/log/', includes:[/(platform-setup.*)], excludes:[null]
2026-01-22 00:15:51,103 INFO dsm-1: Updated DiskSpaceManager configuration in 140 milliseconds
2026-01-22 00:15:51,104 INFO dsm-1: DiskSpaceManager lastSuccessTime = 2026-01-22T00:14:50.959937482Z , lastFailTime = null
2026-01-22 00:15:51,105 INFO dsm-1: cycle 10 disk: /mnt freeDiskSpaceMb: 27074/27582 MB freeDiskSpaceRatio:0.98
2026-01-22 00:15:51,105 INFO dsm-1: Disk /mnt had sufficient free space, skipping directories scan for this cycle
2026-01-22 00:15:51,105 INFO dsm-1: cycle 10 disk: /emr freeDiskSpaceMb: 4987/5056 MB freeDiskSpaceRatio:0.99
2026-01-22 00:15:51,105 INFO dsm-1: Disk /emr had sufficient free space, skipping directories scan for this cycle
2026-01-22 00:15:51,105 INFO dsm-1: DSM cycle finished in 143 milliseconds
2026-01-22 00:16:22,923 INFO CloudWatchAgentUpdater-1: CloudWatchAgentUpdater cycle started
2026-01-22 00:16:22,923 INFO CloudWatchAgentUpdater-1: CloudWatch config indicator file directory does not exist yet. Nothing to load...
2026-01-22 00:16:22,923 INFO CloudWatchAgentUpdater-1: CloudWatchAgentUpdater cycle started: discovered 0 configs, 0 marked for removal
2026-01-22 00:16:51,107 INFO dsm-1: DiskSpaceManager started cycle 11
2026-01-22 00:16:51,107 INFO dsm-1: /mnt   total   27582 MB free   27074 MB used    508 MB (1.84 %)
2026-01-22 00:16:51,107 INFO dsm-1: /emr   total    5056 MB free    4986 MB used     70 MB (1.38 %)
2026-01-22 00:16:51,108 INFO dsm-1: /      total   15283 MB free    8370 MB used   6913 MB (45.23 %)
2026-01-22 00:16:51,109 INFO dsm-1: DiskSpaceManager lastSuccessTime = 2026-01-22T00:15:51.105449587Z , lastFailTime = null
2026-01-22 00:16:51,109 INFO dsm-1: cycle 11 disk: /mnt freeDiskSpaceMb: 27074/27582 MB freeDiskSpaceRatio:0.98
2026-01-22 00:16:51,109 INFO dsm-1: Disk /mnt had sufficient free space, skipping directories scan for this cycle
2026-01-22 00:16:51,110 INFO dsm-1: cycle 11 disk: /emr freeDiskSpaceMb: 4986/5056 MB freeDiskSpaceRatio:0.99
2026-01-22 00:16:51,110 INFO dsm-1: Disk /emr had sufficient free space, skipping directories scan for this cycle
2026-01-22 00:16:51,110 INFO dsm-1: DSM cycle finished in 2 milliseconds

# dump log pusher stdout
tail -n 100 /emr/logpusher/log/logpusher.out
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.

if [ "$dumpType" == "full" ]; then 
  echo "Kicking off a dump-jstack run in the background."
  timeout -s SIGKILL 2h /usr/bin/dump-jstack > /emr/instance-state/jstack.log-`date +\%Y-\%m-\%d-\%H-\%M` 2>&1 &
fi
Kicking off a dump-jstack run in the background.

# dump service nanny log
tail -n 20 /emr/service-nanny/log/service-nanny-`date +%Y-%m-%d`
tail: cannot open '/emr/service-nanny/log/service-nanny-2026-01-22' for reading: No such file or directory

# dump mysql process list
mysqladmin -u root processlist | awk -F'|' '{print $6, $7, $8, $9}' | grep -v '^\s*$'
mysqladmin: connect to server at 'localhost' failed
error: 'Can't connect to local server through socket '/var/lib/mysql/mysql.sock' (2)'
Check that mariadbd is running and that the socket: '/var/lib/mysql/mysql.sock' exists!

# Can we contact dom0?
curl --connect-timeout 2 -q -f --retry 5 -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 1" >/dev/null
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100    56  100    56    0     0  17554      0 --:--:-- --:--:-- --:--:-- 18666

# Can we access master?
set +o verbose
PING 172.31.47.200 (172.31.47.200) 56(84) bytes of data.
64 bytes from 172.31.47.200: icmp_seq=1 ttl=127 time=0.221 ms
64 bytes from 172.31.47.200: icmp_seq=2 ttl=127 time=0.198 ms

--- 172.31.47.200 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1016ms
rtt min/avg/max/mdev = 0.198/0.209/0.221/0.011 ms

traceroute to 172.31.47.200 (172.31.47.200), 10 hops max, 60 byte packets
 1  172.31.47.200  0.188 ms  0.149 ms  0.132 ms


# Can we access the outside world?
curl -s -I --connect-timeout 1 --max-time 5 http://elasticmapreduce.s3.amazonaws.com | head
HTTP/1.1 200 OK
x-amz-id-2: DfxHkYwcBq3lQk29jlLin2VJ0Nm/xzsOO93k2ahyjxcd5pcJSVT/lvqKXntwkZtIpcZ/0RM3a5C7wO7NEQK7w71AtzM1iVYP
x-amz-request-id: ZSCD9670QCVQXVFH
Date: Thu, 22 Jan 2026 00:17:30 GMT
x-amz-bucket-region: us-east-1
x-amz-access-point-alias: false
x-amz-bucket-arn: arn:aws:s3:::elasticmapreduce
Content-Type: application/xml
Transfer-Encoding: chunked
Server: AmazonS3

# Now traceroute it
traceroute -T --sport=17241 -p 443 -w 3 -n -m 10 elasticmapreduce.s3.amazonaws.com
traceroute to elasticmapreduce.s3.amazonaws.com (3.5.29.144), 10 hops max, 60 byte packets
 1  *